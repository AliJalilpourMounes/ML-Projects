{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e30b210b",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-01-30T12:12:32.822326Z",
          "iopub.status.busy": "2023-01-30T12:12:32.821666Z",
          "iopub.status.idle": "2023-01-30T12:12:34.206984Z",
          "shell.execute_reply": "2023-01-30T12:12:34.205265Z"
        },
        "papermill": {
          "duration": 1.411614,
          "end_time": "2023-01-30T12:12:34.210089",
          "exception": false,
          "start_time": "2023-01-30T12:12:32.798475",
          "status": "completed"
        },
        "tags": [],
        "id": "e30b210b",
        "outputId": "f3dc0516-f43a-434a-d216-61df6c1d166a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/kaggle/input/playground-series-s3e4/sample_submission.csv\n",
            "/kaggle/input/playground-series-s3e4/train.csv\n",
            "/kaggle/input/playground-series-s3e4/test.csv\n",
            "/kaggle/input/creditcardfraud/creditcard.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import optuna\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b93c4927",
      "metadata": {
        "papermill": {
          "duration": 0.013453,
          "end_time": "2023-01-30T12:12:34.237858",
          "exception": false,
          "start_time": "2023-01-30T12:12:34.224405",
          "status": "completed"
        },
        "tags": [],
        "id": "b93c4927"
      },
      "source": [
        "**Downloading data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a9d0a21",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:12:34.270037Z",
          "iopub.status.busy": "2023-01-30T12:12:34.269638Z",
          "iopub.status.idle": "2023-01-30T12:12:46.498448Z",
          "shell.execute_reply": "2023-01-30T12:12:46.497450Z"
        },
        "papermill": {
          "duration": 12.247434,
          "end_time": "2023-01-30T12:12:46.501288",
          "exception": false,
          "start_time": "2023-01-30T12:12:34.253854",
          "status": "completed"
        },
        "tags": [],
        "id": "4a9d0a21"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('/kaggle/input/playground-series-s3e4/train.csv')\n",
        "test_df = pd.read_csv('/kaggle/input/playground-series-s3e4/test.csv')\n",
        "submission = pd.read_csv('/kaggle/input/playground-series-s3e4/sample_submission.csv')\n",
        "addition_data = pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv')\n",
        "\n",
        "train_df['is_generated'] = 1\n",
        "test_df['is_generated'] = 1\n",
        "addition_data['is_generated'] = 0\n",
        "\n",
        "# addition_data = addition_data[addition_data['Class']==1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16a0b2f7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:12:46.531953Z",
          "iopub.status.busy": "2023-01-30T12:12:46.530591Z",
          "iopub.status.idle": "2023-01-30T12:12:46.660199Z",
          "shell.execute_reply": "2023-01-30T12:12:46.659104Z"
        },
        "papermill": {
          "duration": 0.147508,
          "end_time": "2023-01-30T12:12:46.662929",
          "exception": false,
          "start_time": "2023-01-30T12:12:46.515421",
          "status": "completed"
        },
        "tags": [],
        "id": "16a0b2f7",
        "outputId": "9cd83b7e-cac2-49aa-c418-651162bce7f8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "      <th>is_generated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284802</th>\n",
              "      <td>172786.0</td>\n",
              "      <td>-11.881118</td>\n",
              "      <td>10.071785</td>\n",
              "      <td>-9.834783</td>\n",
              "      <td>-2.066656</td>\n",
              "      <td>-5.364473</td>\n",
              "      <td>-2.606837</td>\n",
              "      <td>-4.918215</td>\n",
              "      <td>7.305334</td>\n",
              "      <td>1.914428</td>\n",
              "      <td>...</td>\n",
              "      <td>0.111864</td>\n",
              "      <td>1.014480</td>\n",
              "      <td>-0.509348</td>\n",
              "      <td>1.436807</td>\n",
              "      <td>0.250034</td>\n",
              "      <td>0.943651</td>\n",
              "      <td>0.823731</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284803</th>\n",
              "      <td>172787.0</td>\n",
              "      <td>-0.732789</td>\n",
              "      <td>-0.055080</td>\n",
              "      <td>2.035030</td>\n",
              "      <td>-0.738589</td>\n",
              "      <td>0.868229</td>\n",
              "      <td>1.058415</td>\n",
              "      <td>0.024330</td>\n",
              "      <td>0.294869</td>\n",
              "      <td>0.584800</td>\n",
              "      <td>...</td>\n",
              "      <td>0.924384</td>\n",
              "      <td>0.012463</td>\n",
              "      <td>-1.016226</td>\n",
              "      <td>-0.606624</td>\n",
              "      <td>-0.395255</td>\n",
              "      <td>0.068472</td>\n",
              "      <td>-0.053527</td>\n",
              "      <td>24.79</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284804</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>1.919565</td>\n",
              "      <td>-0.301254</td>\n",
              "      <td>-3.249640</td>\n",
              "      <td>-0.557828</td>\n",
              "      <td>2.630515</td>\n",
              "      <td>3.031260</td>\n",
              "      <td>-0.296827</td>\n",
              "      <td>0.708417</td>\n",
              "      <td>0.432454</td>\n",
              "      <td>...</td>\n",
              "      <td>0.578229</td>\n",
              "      <td>-0.037501</td>\n",
              "      <td>0.640134</td>\n",
              "      <td>0.265745</td>\n",
              "      <td>-0.087371</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>-0.026561</td>\n",
              "      <td>67.88</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284805</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>-0.240440</td>\n",
              "      <td>0.530483</td>\n",
              "      <td>0.702510</td>\n",
              "      <td>0.689799</td>\n",
              "      <td>-0.377961</td>\n",
              "      <td>0.623708</td>\n",
              "      <td>-0.686180</td>\n",
              "      <td>0.679145</td>\n",
              "      <td>0.392087</td>\n",
              "      <td>...</td>\n",
              "      <td>0.800049</td>\n",
              "      <td>-0.163298</td>\n",
              "      <td>0.123205</td>\n",
              "      <td>-0.569159</td>\n",
              "      <td>0.546668</td>\n",
              "      <td>0.108821</td>\n",
              "      <td>0.104533</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284806</th>\n",
              "      <td>172792.0</td>\n",
              "      <td>-0.533413</td>\n",
              "      <td>-0.189733</td>\n",
              "      <td>0.703337</td>\n",
              "      <td>-0.506271</td>\n",
              "      <td>-0.012546</td>\n",
              "      <td>-0.649617</td>\n",
              "      <td>1.577006</td>\n",
              "      <td>-0.414650</td>\n",
              "      <td>0.486180</td>\n",
              "      <td>...</td>\n",
              "      <td>0.643078</td>\n",
              "      <td>0.376777</td>\n",
              "      <td>0.008797</td>\n",
              "      <td>-0.473649</td>\n",
              "      <td>-0.818267</td>\n",
              "      <td>-0.002415</td>\n",
              "      <td>0.013649</td>\n",
              "      <td>217.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>284807 rows × 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Time         V1         V2        V3        V4        V5  \\\n",
              "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
              "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
              "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
              "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
              "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
              "...          ...        ...        ...       ...       ...       ...   \n",
              "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
              "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
              "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
              "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
              "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
              "\n",
              "              V6        V7        V8        V9  ...       V22       V23  \\\n",
              "0       0.462388  0.239599  0.098698  0.363787  ...  0.277838 -0.110474   \n",
              "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.638672  0.101288   \n",
              "2       1.800499  0.791461  0.247676 -1.514654  ...  0.771679  0.909412   \n",
              "3       1.247203  0.237609  0.377436 -1.387024  ...  0.005274 -0.190321   \n",
              "4       0.095921  0.592941 -0.270533  0.817739  ...  0.798278 -0.137458   \n",
              "...          ...       ...       ...       ...  ...       ...       ...   \n",
              "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.111864  1.014480   \n",
              "284803  1.058415  0.024330  0.294869  0.584800  ...  0.924384  0.012463   \n",
              "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.578229 -0.037501   \n",
              "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.800049 -0.163298   \n",
              "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.643078  0.376777   \n",
              "\n",
              "             V24       V25       V26       V27       V28  Amount  Class  \\\n",
              "0       0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0   \n",
              "1      -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      0   \n",
              "2      -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0   \n",
              "3      -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0   \n",
              "4       0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0   \n",
              "...          ...       ...       ...       ...       ...     ...    ...   \n",
              "284802 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77      0   \n",
              "284803 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79      0   \n",
              "284804  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88      0   \n",
              "284805  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00      0   \n",
              "284806  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00      0   \n",
              "\n",
              "        is_generated  \n",
              "0                  0  \n",
              "1                  0  \n",
              "2                  0  \n",
              "3                  0  \n",
              "4                  0  \n",
              "...              ...  \n",
              "284802             0  \n",
              "284803             0  \n",
              "284804             0  \n",
              "284805             0  \n",
              "284806             0  \n",
              "\n",
              "[284807 rows x 32 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "addition_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c3f8c59",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:12:46.694909Z",
          "iopub.status.busy": "2023-01-30T12:12:46.693425Z",
          "iopub.status.idle": "2023-01-30T12:12:46.759314Z",
          "shell.execute_reply": "2023-01-30T12:12:46.758058Z"
        },
        "papermill": {
          "duration": 0.084678,
          "end_time": "2023-01-30T12:12:46.762100",
          "exception": false,
          "start_time": "2023-01-30T12:12:46.677422",
          "status": "completed"
        },
        "tags": [],
        "id": "9c3f8c59"
      },
      "outputs": [],
      "source": [
        "train_df = pd.concat([train_df, addition_data],axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1283d8ac",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:12:46.792229Z",
          "iopub.status.busy": "2023-01-30T12:12:46.791814Z",
          "iopub.status.idle": "2023-01-30T12:12:46.796931Z",
          "shell.execute_reply": "2023-01-30T12:12:46.795734Z"
        },
        "papermill": {
          "duration": 0.023059,
          "end_time": "2023-01-30T12:12:46.799368",
          "exception": false,
          "start_time": "2023-01-30T12:12:46.776309",
          "status": "completed"
        },
        "tags": [],
        "id": "1283d8ac"
      },
      "outputs": [],
      "source": [
        "# train_df.drop_duplicates(inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1f516eb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:12:46.831287Z",
          "iopub.status.busy": "2023-01-30T12:12:46.830876Z",
          "iopub.status.idle": "2023-01-30T12:12:47.020845Z",
          "shell.execute_reply": "2023-01-30T12:12:47.019661Z"
        },
        "papermill": {
          "duration": 0.209543,
          "end_time": "2023-01-30T12:12:47.023560",
          "exception": false,
          "start_time": "2023-01-30T12:12:46.814017",
          "status": "completed"
        },
        "tags": [],
        "id": "d1f516eb",
        "outputId": "9f257c72-4ed2-459e-9442-fde16b261a61"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>...</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "      <th>is_generated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.074329</td>\n",
              "      <td>-0.129425</td>\n",
              "      <td>-1.137418</td>\n",
              "      <td>0.412846</td>\n",
              "      <td>-0.192638</td>\n",
              "      <td>-1.210144</td>\n",
              "      <td>0.110697</td>\n",
              "      <td>-0.263477</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.887840</td>\n",
              "      <td>0.336701</td>\n",
              "      <td>-0.110835</td>\n",
              "      <td>-0.291459</td>\n",
              "      <td>0.207733</td>\n",
              "      <td>-0.076576</td>\n",
              "      <td>-0.059577</td>\n",
              "      <td>1.98</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.998827</td>\n",
              "      <td>-1.250891</td>\n",
              "      <td>-0.520969</td>\n",
              "      <td>-0.894539</td>\n",
              "      <td>-1.122528</td>\n",
              "      <td>-0.270866</td>\n",
              "      <td>-1.029289</td>\n",
              "      <td>0.050198</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.038367</td>\n",
              "      <td>0.133518</td>\n",
              "      <td>-0.461928</td>\n",
              "      <td>-0.465491</td>\n",
              "      <td>-0.464655</td>\n",
              "      <td>-0.009413</td>\n",
              "      <td>-0.038238</td>\n",
              "      <td>84.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.091535</td>\n",
              "      <td>1.004517</td>\n",
              "      <td>-0.223445</td>\n",
              "      <td>-0.435249</td>\n",
              "      <td>0.667548</td>\n",
              "      <td>-0.988351</td>\n",
              "      <td>0.948146</td>\n",
              "      <td>-0.084789</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.803736</td>\n",
              "      <td>0.154495</td>\n",
              "      <td>0.951233</td>\n",
              "      <td>-0.506919</td>\n",
              "      <td>0.085046</td>\n",
              "      <td>0.224458</td>\n",
              "      <td>0.087356</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.979649</td>\n",
              "      <td>-0.184949</td>\n",
              "      <td>-1.064206</td>\n",
              "      <td>0.120125</td>\n",
              "      <td>-0.215238</td>\n",
              "      <td>-0.648829</td>\n",
              "      <td>-0.087826</td>\n",
              "      <td>-0.035367</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.079792</td>\n",
              "      <td>0.167701</td>\n",
              "      <td>-0.042939</td>\n",
              "      <td>0.000799</td>\n",
              "      <td>-0.096148</td>\n",
              "      <td>-0.057780</td>\n",
              "      <td>-0.073839</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.025898</td>\n",
              "      <td>-0.171827</td>\n",
              "      <td>1.203717</td>\n",
              "      <td>1.243900</td>\n",
              "      <td>-0.636572</td>\n",
              "      <td>1.099074</td>\n",
              "      <td>-0.938651</td>\n",
              "      <td>0.569239</td>\n",
              "      <td>...</td>\n",
              "      <td>0.608908</td>\n",
              "      <td>0.027901</td>\n",
              "      <td>-0.262813</td>\n",
              "      <td>0.257834</td>\n",
              "      <td>-0.252829</td>\n",
              "      <td>0.108338</td>\n",
              "      <td>0.021051</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503931</th>\n",
              "      <td>NaN</td>\n",
              "      <td>172786.0</td>\n",
              "      <td>-11.881118</td>\n",
              "      <td>10.071785</td>\n",
              "      <td>-9.834783</td>\n",
              "      <td>-2.066656</td>\n",
              "      <td>-5.364473</td>\n",
              "      <td>-2.606837</td>\n",
              "      <td>-4.918215</td>\n",
              "      <td>7.305334</td>\n",
              "      <td>...</td>\n",
              "      <td>0.111864</td>\n",
              "      <td>1.014480</td>\n",
              "      <td>-0.509348</td>\n",
              "      <td>1.436807</td>\n",
              "      <td>0.250034</td>\n",
              "      <td>0.943651</td>\n",
              "      <td>0.823731</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503932</th>\n",
              "      <td>NaN</td>\n",
              "      <td>172787.0</td>\n",
              "      <td>-0.732789</td>\n",
              "      <td>-0.055080</td>\n",
              "      <td>2.035030</td>\n",
              "      <td>-0.738589</td>\n",
              "      <td>0.868229</td>\n",
              "      <td>1.058415</td>\n",
              "      <td>0.024330</td>\n",
              "      <td>0.294869</td>\n",
              "      <td>...</td>\n",
              "      <td>0.924384</td>\n",
              "      <td>0.012463</td>\n",
              "      <td>-1.016226</td>\n",
              "      <td>-0.606624</td>\n",
              "      <td>-0.395255</td>\n",
              "      <td>0.068472</td>\n",
              "      <td>-0.053527</td>\n",
              "      <td>24.79</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503933</th>\n",
              "      <td>NaN</td>\n",
              "      <td>172788.0</td>\n",
              "      <td>1.919565</td>\n",
              "      <td>-0.301254</td>\n",
              "      <td>-3.249640</td>\n",
              "      <td>-0.557828</td>\n",
              "      <td>2.630515</td>\n",
              "      <td>3.031260</td>\n",
              "      <td>-0.296827</td>\n",
              "      <td>0.708417</td>\n",
              "      <td>...</td>\n",
              "      <td>0.578229</td>\n",
              "      <td>-0.037501</td>\n",
              "      <td>0.640134</td>\n",
              "      <td>0.265745</td>\n",
              "      <td>-0.087371</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>-0.026561</td>\n",
              "      <td>67.88</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503934</th>\n",
              "      <td>NaN</td>\n",
              "      <td>172788.0</td>\n",
              "      <td>-0.240440</td>\n",
              "      <td>0.530483</td>\n",
              "      <td>0.702510</td>\n",
              "      <td>0.689799</td>\n",
              "      <td>-0.377961</td>\n",
              "      <td>0.623708</td>\n",
              "      <td>-0.686180</td>\n",
              "      <td>0.679145</td>\n",
              "      <td>...</td>\n",
              "      <td>0.800049</td>\n",
              "      <td>-0.163298</td>\n",
              "      <td>0.123205</td>\n",
              "      <td>-0.569159</td>\n",
              "      <td>0.546668</td>\n",
              "      <td>0.108821</td>\n",
              "      <td>0.104533</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503935</th>\n",
              "      <td>NaN</td>\n",
              "      <td>172792.0</td>\n",
              "      <td>-0.533413</td>\n",
              "      <td>-0.189733</td>\n",
              "      <td>0.703337</td>\n",
              "      <td>-0.506271</td>\n",
              "      <td>-0.012546</td>\n",
              "      <td>-0.649617</td>\n",
              "      <td>1.577006</td>\n",
              "      <td>-0.414650</td>\n",
              "      <td>...</td>\n",
              "      <td>0.643078</td>\n",
              "      <td>0.376777</td>\n",
              "      <td>0.008797</td>\n",
              "      <td>-0.473649</td>\n",
              "      <td>-0.818267</td>\n",
              "      <td>-0.002415</td>\n",
              "      <td>0.013649</td>\n",
              "      <td>217.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>503936 rows × 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id      Time         V1         V2        V3        V4        V5  \\\n",
              "0       0.0       0.0   2.074329  -0.129425 -1.137418  0.412846 -0.192638   \n",
              "1       1.0       0.0   1.998827  -1.250891 -0.520969 -0.894539 -1.122528   \n",
              "2       2.0       0.0   0.091535   1.004517 -0.223445 -0.435249  0.667548   \n",
              "3       3.0       0.0   1.979649  -0.184949 -1.064206  0.120125 -0.215238   \n",
              "4       4.0       0.0   1.025898  -0.171827  1.203717  1.243900 -0.636572   \n",
              "...     ...       ...        ...        ...       ...       ...       ...   \n",
              "503931  NaN  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
              "503932  NaN  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
              "503933  NaN  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
              "503934  NaN  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
              "503935  NaN  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
              "\n",
              "              V6        V7        V8  ...       V22       V23       V24  \\\n",
              "0      -1.210144  0.110697 -0.263477  ... -0.887840  0.336701 -0.110835   \n",
              "1      -0.270866 -1.029289  0.050198  ... -0.038367  0.133518 -0.461928   \n",
              "2      -0.988351  0.948146 -0.084789  ... -0.803736  0.154495  0.951233   \n",
              "3      -0.648829 -0.087826 -0.035367  ... -0.079792  0.167701 -0.042939   \n",
              "4       1.099074 -0.938651  0.569239  ...  0.608908  0.027901 -0.262813   \n",
              "...          ...       ...       ...  ...       ...       ...       ...   \n",
              "503931 -2.606837 -4.918215  7.305334  ...  0.111864  1.014480 -0.509348   \n",
              "503932  1.058415  0.024330  0.294869  ...  0.924384  0.012463 -1.016226   \n",
              "503933  3.031260 -0.296827  0.708417  ...  0.578229 -0.037501  0.640134   \n",
              "503934  0.623708 -0.686180  0.679145  ...  0.800049 -0.163298  0.123205   \n",
              "503935 -0.649617  1.577006 -0.414650  ...  0.643078  0.376777  0.008797   \n",
              "\n",
              "             V25       V26       V27       V28  Amount  Class  is_generated  \n",
              "0      -0.291459  0.207733 -0.076576 -0.059577    1.98      0             1  \n",
              "1      -0.465491 -0.464655 -0.009413 -0.038238   84.00      0             1  \n",
              "2      -0.506919  0.085046  0.224458  0.087356    2.69      0             1  \n",
              "3       0.000799 -0.096148 -0.057780 -0.073839    1.00      0             1  \n",
              "4       0.257834 -0.252829  0.108338  0.021051    1.00      0             1  \n",
              "...          ...       ...       ...       ...     ...    ...           ...  \n",
              "503931  1.436807  0.250034  0.943651  0.823731    0.77      0             0  \n",
              "503932 -0.606624 -0.395255  0.068472 -0.053527   24.79      0             0  \n",
              "503933  0.265745 -0.087371  0.004455 -0.026561   67.88      0             0  \n",
              "503934 -0.569159  0.546668  0.108821  0.104533   10.00      0             0  \n",
              "503935 -0.473649 -0.818267 -0.002415  0.013649  217.00      0             0  \n",
              "\n",
              "[503936 rows x 33 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4052cc08",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:12:47.056483Z",
          "iopub.status.busy": "2023-01-30T12:12:47.056081Z",
          "iopub.status.idle": "2023-01-30T12:12:47.336803Z",
          "shell.execute_reply": "2023-01-30T12:12:47.335556Z"
        },
        "papermill": {
          "duration": 0.300209,
          "end_time": "2023-01-30T12:12:47.339417",
          "exception": false,
          "start_time": "2023-01-30T12:12:47.039208",
          "status": "completed"
        },
        "tags": [],
        "id": "4052cc08",
        "outputId": "ede3fe39-18ba-4fca-ff5e-d9d939564c21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_df.Class.hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f85b7ec0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:12:47.372295Z",
          "iopub.status.busy": "2023-01-30T12:12:47.371710Z",
          "iopub.status.idle": "2023-01-30T12:12:47.447045Z",
          "shell.execute_reply": "2023-01-30T12:12:47.445699Z"
        },
        "papermill": {
          "duration": 0.095284,
          "end_time": "2023-01-30T12:12:47.449997",
          "exception": false,
          "start_time": "2023-01-30T12:12:47.354713",
          "status": "completed"
        },
        "tags": [],
        "id": "f85b7ec0"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([train_df, test_df], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "506f517f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:12:47.482277Z",
          "iopub.status.busy": "2023-01-30T12:12:47.481845Z",
          "iopub.status.idle": "2023-01-30T12:12:47.539839Z",
          "shell.execute_reply": "2023-01-30T12:12:47.538757Z"
        },
        "papermill": {
          "duration": 0.077167,
          "end_time": "2023-01-30T12:12:47.542516",
          "exception": false,
          "start_time": "2023-01-30T12:12:47.465349",
          "status": "completed"
        },
        "tags": [],
        "id": "506f517f"
      },
      "outputs": [],
      "source": [
        "df['hour'] = df['Time'] % (24 * 3600) // 3600\n",
        "df['day'] = (df['Time'] // (24 * 3600)) % 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35a0d46a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:12:47.579429Z",
          "iopub.status.busy": "2023-01-30T12:12:47.578977Z",
          "iopub.status.idle": "2023-01-30T12:12:49.516932Z",
          "shell.execute_reply": "2023-01-30T12:12:49.515557Z"
        },
        "papermill": {
          "duration": 1.960737,
          "end_time": "2023-01-30T12:12:49.519714",
          "exception": false,
          "start_time": "2023-01-30T12:12:47.558977",
          "status": "completed"
        },
        "tags": [],
        "id": "35a0d46a"
      },
      "outputs": [],
      "source": [
        "def across_col_feat(df):\n",
        "    '''\n",
        "    Calculates features across colums...\n",
        "    '''\n",
        "    features = [feat for feat in df.columns if 'V' in feat]\n",
        "    df['V_Sum'] = df[features].sum(axis = 1)\n",
        "    df['V_Min'] = df[features].min(axis = 1)\n",
        "    df['V_Max'] = df[features].max(axis = 1)\n",
        "    df['V_Avg'] = df[features].mean(axis = 1)\n",
        "    df['V_Std'] = df[features].std(axis = 1)\n",
        "    df['V_Pos'] = df[features].gt(0).sum(axis = 1)\n",
        "    df['V_Neg'] = df[features].lt(0).sum(axis = 1)\n",
        "    df['V_Range'] = abs(df['V_Min'] - df['V_Max'])\n",
        "\n",
        "    return df\n",
        "\n",
        "df = across_col_feat(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a12508c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:12:49.552142Z",
          "iopub.status.busy": "2023-01-30T12:12:49.551744Z",
          "iopub.status.idle": "2023-01-30T12:12:49.556669Z",
          "shell.execute_reply": "2023-01-30T12:12:49.555347Z"
        },
        "papermill": {
          "duration": 0.024095,
          "end_time": "2023-01-30T12:12:49.559150",
          "exception": false,
          "start_time": "2023-01-30T12:12:49.535055",
          "status": "completed"
        },
        "tags": [],
        "id": "4a12508c"
      },
      "outputs": [],
      "source": [
        "# df['V20_div_Amount'] = df.V20 / (df.Amount + 1e-6)\n",
        "# df['V23_div_Amount'] = df.V23 / (df.Amount + 1e-6)\n",
        "# df['V27_div_28'] = df.V27 / (df.V28 + 5e-8)\n",
        "# df['V20_div_Amount_div_V27_div_28'] = df['V20_div_Amount'] / (df['V27_div_28'] + 1e-6)\n",
        "# df['V23_div_Amount_div_V27_div_28'] = df['V23_div_Amount'] / (df['V27_div_28'] + 1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba7a98f1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:12:49.591281Z",
          "iopub.status.busy": "2023-01-30T12:12:49.590858Z",
          "iopub.status.idle": "2023-01-30T12:12:49.595764Z",
          "shell.execute_reply": "2023-01-30T12:12:49.594611Z"
        },
        "papermill": {
          "duration": 0.023553,
          "end_time": "2023-01-30T12:12:49.598014",
          "exception": false,
          "start_time": "2023-01-30T12:12:49.574461",
          "status": "completed"
        },
        "tags": [],
        "id": "ba7a98f1"
      },
      "outputs": [],
      "source": [
        "# from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# scaler = StandardScaler()\n",
        "\n",
        "# y = df['Class']\n",
        "# df = df.drop(['id','Class'], axis=1)\n",
        "\n",
        "# df[df.columns] = scaler.fit_transform(df[df.columns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ead28996",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:12:49.630184Z",
          "iopub.status.busy": "2023-01-30T12:12:49.629221Z",
          "iopub.status.idle": "2023-01-30T12:12:51.425842Z",
          "shell.execute_reply": "2023-01-30T12:12:51.424689Z"
        },
        "papermill": {
          "duration": 1.815676,
          "end_time": "2023-01-30T12:12:51.428756",
          "exception": false,
          "start_time": "2023-01-30T12:12:49.613080",
          "status": "completed"
        },
        "tags": [],
        "id": "ead28996"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "rscale = RobustScaler()\n",
        "\n",
        "y = df['Class']\n",
        "df = df.drop(['id','Class'], axis=1)\n",
        "\n",
        "# df['Amount']=rscale.fit_transform(df['Amount'].values.reshape(-1,1))\n",
        "# df['Time']=rscale.fit_transform(df['Time'].values.reshape(-1,1))\n",
        "\n",
        "df[df.columns] = rscale.fit_transform(df[df.columns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3febd01b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:12:51.460723Z",
          "iopub.status.busy": "2023-01-30T12:12:51.460315Z",
          "iopub.status.idle": "2023-01-30T12:12:51.656184Z",
          "shell.execute_reply": "2023-01-30T12:12:51.654945Z"
        },
        "papermill": {
          "duration": 0.215107,
          "end_time": "2023-01-30T12:12:51.659015",
          "exception": false,
          "start_time": "2023-01-30T12:12:51.443908",
          "status": "completed"
        },
        "tags": [],
        "id": "3febd01b",
        "outputId": "04b24583-10bf-4a23-9e81-76e15db73a06"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>hour</th>\n",
              "      <th>day</th>\n",
              "      <th>V_Sum</th>\n",
              "      <th>V_Min</th>\n",
              "      <th>V_Max</th>\n",
              "      <th>V_Avg</th>\n",
              "      <th>V_Std</th>\n",
              "      <th>V_Pos</th>\n",
              "      <th>V_Neg</th>\n",
              "      <th>V_Range</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.008662</td>\n",
              "      <td>0.891381</td>\n",
              "      <td>-0.125143</td>\n",
              "      <td>-0.700428</td>\n",
              "      <td>0.307221</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>-0.835775</td>\n",
              "      <td>0.093900</td>\n",
              "      <td>-0.610947</td>\n",
              "      <td>0.666656</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.709796</td>\n",
              "      <td>0.502942</td>\n",
              "      <td>0.268731</td>\n",
              "      <td>-0.709796</td>\n",
              "      <td>-0.449470</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>-0.180941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.008662</td>\n",
              "      <td>0.856978</td>\n",
              "      <td>-0.908666</td>\n",
              "      <td>-0.375086</td>\n",
              "      <td>-0.508814</td>\n",
              "      <td>-0.801136</td>\n",
              "      <td>-0.027915</td>\n",
              "      <td>-0.900964</td>\n",
              "      <td>-0.012667</td>\n",
              "      <td>-0.021900</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.430501</td>\n",
              "      <td>0.459923</td>\n",
              "      <td>0.179102</td>\n",
              "      <td>-0.430501</td>\n",
              "      <td>-0.146562</td>\n",
              "      <td>-1.25</td>\n",
              "      <td>1.25</td>\n",
              "      <td>-0.202530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.008662</td>\n",
              "      <td>-0.012076</td>\n",
              "      <td>0.667096</td>\n",
              "      <td>-0.218062</td>\n",
              "      <td>-0.222138</td>\n",
              "      <td>0.532603</td>\n",
              "      <td>-0.645014</td>\n",
              "      <td>0.824740</td>\n",
              "      <td>-0.270132</td>\n",
              "      <td>0.032985</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.524849</td>\n",
              "      <td>0.737101</td>\n",
              "      <td>-1.001244</td>\n",
              "      <td>-0.524849</td>\n",
              "      <td>-0.822400</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>-0.983237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.008662</td>\n",
              "      <td>0.848240</td>\n",
              "      <td>-0.163936</td>\n",
              "      <td>-0.661789</td>\n",
              "      <td>0.124512</td>\n",
              "      <td>-0.125138</td>\n",
              "      <td>-0.352995</td>\n",
              "      <td>-0.079350</td>\n",
              "      <td>-0.175867</td>\n",
              "      <td>0.782772</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.233557</td>\n",
              "      <td>0.191832</td>\n",
              "      <td>0.156336</td>\n",
              "      <td>-0.233557</td>\n",
              "      <td>-0.476091</td>\n",
              "      <td>-1.25</td>\n",
              "      <td>1.25</td>\n",
              "      <td>-0.056709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.008662</td>\n",
              "      <td>0.413665</td>\n",
              "      <td>-0.154768</td>\n",
              "      <td>0.535149</td>\n",
              "      <td>0.825943</td>\n",
              "      <td>-0.439063</td>\n",
              "      <td>1.150352</td>\n",
              "      <td>-0.821865</td>\n",
              "      <td>0.977309</td>\n",
              "      <td>0.626673</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.928013</td>\n",
              "      <td>0.789572</td>\n",
              "      <td>-0.541977</td>\n",
              "      <td>0.928013</td>\n",
              "      <td>-0.470722</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.773793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146082</th>\n",
              "      <td>1.088941</td>\n",
              "      <td>-0.355348</td>\n",
              "      <td>-0.469970</td>\n",
              "      <td>0.288081</td>\n",
              "      <td>-0.296301</td>\n",
              "      <td>0.683361</td>\n",
              "      <td>-0.129952</td>\n",
              "      <td>0.137997</td>\n",
              "      <td>0.024995</td>\n",
              "      <td>0.631654</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.174076</td>\n",
              "      <td>-0.468049</td>\n",
              "      <td>-1.161062</td>\n",
              "      <td>-1.174076</td>\n",
              "      <td>-0.450348</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.357804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146083</th>\n",
              "      <td>1.088941</td>\n",
              "      <td>-0.098842</td>\n",
              "      <td>0.497589</td>\n",
              "      <td>0.079313</td>\n",
              "      <td>-0.318446</td>\n",
              "      <td>0.569516</td>\n",
              "      <td>-0.020947</td>\n",
              "      <td>0.631111</td>\n",
              "      <td>-0.243084</td>\n",
              "      <td>0.144488</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.467728</td>\n",
              "      <td>0.587503</td>\n",
              "      <td>-0.668498</td>\n",
              "      <td>0.467728</td>\n",
              "      <td>-0.682613</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-0.721107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146084</th>\n",
              "      <td>1.088941</td>\n",
              "      <td>-0.731751</td>\n",
              "      <td>1.201309</td>\n",
              "      <td>0.191020</td>\n",
              "      <td>0.275213</td>\n",
              "      <td>0.077212</td>\n",
              "      <td>0.278027</td>\n",
              "      <td>0.492591</td>\n",
              "      <td>-0.222657</td>\n",
              "      <td>0.334990</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.448856</td>\n",
              "      <td>0.209681</td>\n",
              "      <td>-0.093557</td>\n",
              "      <td>1.448856</td>\n",
              "      <td>-0.313379</td>\n",
              "      <td>1.25</td>\n",
              "      <td>-1.25</td>\n",
              "      <td>-0.197970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146085</th>\n",
              "      <td>1.088953</td>\n",
              "      <td>-0.914950</td>\n",
              "      <td>-0.142920</td>\n",
              "      <td>-0.063985</td>\n",
              "      <td>-1.140743</td>\n",
              "      <td>-1.263569</td>\n",
              "      <td>0.822157</td>\n",
              "      <td>0.853943</td>\n",
              "      <td>-0.508402</td>\n",
              "      <td>-0.382416</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.586508</td>\n",
              "      <td>-0.232731</td>\n",
              "      <td>-0.555834</td>\n",
              "      <td>-1.586508</td>\n",
              "      <td>0.370825</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.179565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146086</th>\n",
              "      <td>1.088953</td>\n",
              "      <td>0.884164</td>\n",
              "      <td>-1.063830</td>\n",
              "      <td>-1.128432</td>\n",
              "      <td>-1.133467</td>\n",
              "      <td>0.900205</td>\n",
              "      <td>3.311247</td>\n",
              "      <td>-1.370886</td>\n",
              "      <td>1.442732</td>\n",
              "      <td>0.029028</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.637668</td>\n",
              "      <td>-0.276464</td>\n",
              "      <td>2.093496</td>\n",
              "      <td>0.637668</td>\n",
              "      <td>1.257685</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>1.232453</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>650023 rows × 41 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Time        V1        V2        V3        V4        V5        V6  \\\n",
              "0      -1.008662  0.891381 -0.125143 -0.700428  0.307221 -0.108300 -0.835775   \n",
              "1      -1.008662  0.856978 -0.908666 -0.375086 -0.508814 -0.801136 -0.027915   \n",
              "2      -1.008662 -0.012076  0.667096 -0.218062 -0.222138  0.532603 -0.645014   \n",
              "3      -1.008662  0.848240 -0.163936 -0.661789  0.124512 -0.125138 -0.352995   \n",
              "4      -1.008662  0.413665 -0.154768  0.535149  0.825943 -0.439063  1.150352   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "146082  1.088941 -0.355348 -0.469970  0.288081 -0.296301  0.683361 -0.129952   \n",
              "146083  1.088941 -0.098842  0.497589  0.079313 -0.318446  0.569516 -0.020947   \n",
              "146084  1.088941 -0.731751  1.201309  0.191020  0.275213  0.077212  0.278027   \n",
              "146085  1.088953 -0.914950 -0.142920 -0.063985 -1.140743 -1.263569  0.822157   \n",
              "146086  1.088953  0.884164 -1.063830 -1.128432 -1.133467  0.900205  3.311247   \n",
              "\n",
              "              V7        V8        V9  ...   hour  day     V_Sum     V_Min  \\\n",
              "0       0.093900 -0.610947  0.666656  ... -1.875  0.0 -0.709796  0.502942   \n",
              "1      -0.900964 -0.012667 -0.021900  ... -1.875  0.0 -0.430501  0.459923   \n",
              "2       0.824740 -0.270132  0.032985  ... -1.875  0.0 -0.524849  0.737101   \n",
              "3      -0.079350 -0.175867  0.782772  ... -1.875  0.0 -0.233557  0.191832   \n",
              "4      -0.821865  0.977309  0.626673  ... -1.875  0.0  0.928013  0.789572   \n",
              "...          ...       ...       ...  ...    ...  ...       ...       ...   \n",
              "146082  0.137997  0.024995  0.631654  ...  1.000  1.0 -1.174076 -0.468049   \n",
              "146083  0.631111 -0.243084  0.144488  ...  1.000  1.0  0.467728  0.587503   \n",
              "146084  0.492591 -0.222657  0.334990  ...  1.000  1.0  1.448856  0.209681   \n",
              "146085  0.853943 -0.508402 -0.382416  ...  1.000  1.0 -1.586508 -0.232731   \n",
              "146086 -1.370886  1.442732  0.029028  ...  1.000  1.0  0.637668 -0.276464   \n",
              "\n",
              "           V_Max     V_Avg     V_Std  V_Pos  V_Neg   V_Range  \n",
              "0       0.268731 -0.709796 -0.449470  -0.75   0.75 -0.180941  \n",
              "1       0.179102 -0.430501 -0.146562  -1.25   1.25 -0.202530  \n",
              "2      -1.001244 -0.524849 -0.822400  -0.75   0.75 -0.983237  \n",
              "3       0.156336 -0.233557 -0.476091  -1.25   1.25 -0.056709  \n",
              "4      -0.541977  0.928013 -0.470722   0.50  -0.50 -0.773793  \n",
              "...          ...       ...       ...    ...    ...       ...  \n",
              "146082 -1.161062 -1.174076 -0.450348  -0.25   0.25 -0.357804  \n",
              "146083 -0.668498  0.467728 -0.682613   0.25  -0.25 -0.721107  \n",
              "146084 -0.093557  1.448856 -0.313379   1.25  -1.25 -0.197970  \n",
              "146085 -0.555834 -1.586508  0.370825  -1.00   1.00 -0.179565  \n",
              "146086  2.093496  0.637668  1.257685   0.50  -0.50  1.232453  \n",
              "\n",
              "[650023 rows x 41 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37855aa0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:12:51.724886Z",
          "iopub.status.busy": "2023-01-30T12:12:51.724467Z",
          "iopub.status.idle": "2023-01-30T12:12:52.056734Z",
          "shell.execute_reply": "2023-01-30T12:12:52.055171Z"
        },
        "papermill": {
          "duration": 0.353391,
          "end_time": "2023-01-30T12:12:52.059844",
          "exception": false,
          "start_time": "2023-01-30T12:12:51.706453",
          "status": "completed"
        },
        "tags": [],
        "id": "37855aa0"
      },
      "outputs": [],
      "source": [
        "train_df = df.iloc[:-len(test_df),:]\n",
        "train_df['Class'] = y[:-len(test_df)]\n",
        "test_df = df.iloc[-len(test_df):,:].reset_index(drop=True)\n",
        "\n",
        "oversample = train_df[train_df['Class']==1]\n",
        "undersample = train_df[train_df['Class']==0]\n",
        "\n",
        "X = train_df.drop(['Class'], axis=1)\n",
        "y = train_df.Class\n",
        "X_test = test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ccacc1d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:12:52.093055Z",
          "iopub.status.busy": "2023-01-30T12:12:52.092619Z",
          "iopub.status.idle": "2023-01-30T12:12:52.098098Z",
          "shell.execute_reply": "2023-01-30T12:12:52.096905Z"
        },
        "papermill": {
          "duration": 0.024956,
          "end_time": "2023-01-30T12:12:52.100631",
          "exception": false,
          "start_time": "2023-01-30T12:12:52.075675",
          "status": "completed"
        },
        "tags": [],
        "id": "9ccacc1d"
      },
      "outputs": [],
      "source": [
        "# oversample1 = oversample[:200]\n",
        "# undersample1 = undersample[:100000]\n",
        "\n",
        "# oversample = oversample[200:]\n",
        "# undersample = undersample[100000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3373e568",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:12:52.134771Z",
          "iopub.status.busy": "2023-01-30T12:12:52.134082Z",
          "iopub.status.idle": "2023-01-30T12:12:52.138791Z",
          "shell.execute_reply": "2023-01-30T12:12:52.137707Z"
        },
        "papermill": {
          "duration": 0.024652,
          "end_time": "2023-01-30T12:12:52.141032",
          "exception": false,
          "start_time": "2023-01-30T12:12:52.116380",
          "status": "completed"
        },
        "tags": [],
        "id": "3373e568"
      },
      "outputs": [],
      "source": [
        "# X1 = X[:50000]\n",
        "# y1 = y[:50000]\n",
        "# X = X[50000:]\n",
        "# y = y[50000:]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec9f3bf4",
      "metadata": {
        "papermill": {
          "duration": 0.015247,
          "end_time": "2023-01-30T12:12:52.171860",
          "exception": false,
          "start_time": "2023-01-30T12:12:52.156613",
          "status": "completed"
        },
        "tags": [],
        "id": "ec9f3bf4"
      },
      "source": [
        "**CatBoost regression model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27e74567",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:12:52.207351Z",
          "iopub.status.busy": "2023-01-30T12:12:52.206961Z",
          "iopub.status.idle": "2023-01-30T12:12:52.212939Z",
          "shell.execute_reply": "2023-01-30T12:12:52.211578Z"
        },
        "papermill": {
          "duration": 0.026189,
          "end_time": "2023-01-30T12:12:52.215051",
          "exception": false,
          "start_time": "2023-01-30T12:12:52.188862",
          "status": "completed"
        },
        "tags": [],
        "id": "27e74567"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# import catboost\n",
        "# from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
        "# from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# def catboost_objective(trial):\n",
        "#     learning_rate = trial.suggest_float('learning_rate', 0, 0.3)\n",
        "#     depth = trial.suggest_int('depth', 3, 10)\n",
        "# #     n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
        "# #     subsample = trial.suggest_float('subsample', 0, 1)\n",
        "# #     l2_leaf_reg = trial.suggest_int('l2_leaf_reg', 1, 100)\n",
        "# #     min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 100)\n",
        "\n",
        "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "\n",
        "#     model = catboost.CatBoostRegressor(\n",
        "#                 random_seed = 1234,\n",
        "# #                 iterations = 5000,\n",
        "# #                 early_stopping_rounds = 1000,\n",
        "# #                 use_best_model = True,\n",
        "#                 eval_metric = 'RMSE',\n",
        "#                 verbose = 5000,\n",
        "\n",
        "#                  depth = depth,\n",
        "#                  learning_rate = learning_rate,\n",
        "#                  rsm = 0.5,\n",
        "#                  subsample = 0.931,\n",
        "#                  l2_leaf_reg = 69,\n",
        "#                  min_data_in_leaf = 20,\n",
        "#                  random_strength = 0.175,\n",
        "#     )\n",
        "\n",
        "#     model.fit(X_train, y_train)\n",
        "\n",
        "# #     kf = KFold(n_splits= 5)\n",
        "# #     cv_score = cross_val_score(model, X, y, scoring= 'roc_auc', cv= kf)\n",
        "#     return roc_auc_score(y_test, model.predict(X_test))\n",
        "\n",
        "# study = optuna.create_study(direction= 'maximize')\n",
        "# study.optimize(catboost_objective, n_trials= 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8914eebd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:12:52.248370Z",
          "iopub.status.busy": "2023-01-30T12:12:52.247956Z",
          "iopub.status.idle": "2023-01-30T12:12:52.252839Z",
          "shell.execute_reply": "2023-01-30T12:12:52.251732Z"
        },
        "papermill": {
          "duration": 0.024597,
          "end_time": "2023-01-30T12:12:52.255243",
          "exception": false,
          "start_time": "2023-01-30T12:12:52.230646",
          "status": "completed"
        },
        "tags": [],
        "id": "8914eebd"
      },
      "outputs": [],
      "source": [
        "# study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb49e8bc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:12:52.288389Z",
          "iopub.status.busy": "2023-01-30T12:12:52.287988Z",
          "iopub.status.idle": "2023-01-30T12:15:50.059031Z",
          "shell.execute_reply": "2023-01-30T12:15:50.057824Z"
        },
        "papermill": {
          "duration": 177.791139,
          "end_time": "2023-01-30T12:15:50.061995",
          "exception": false,
          "start_time": "2023-01-30T12:12:52.270856",
          "status": "completed"
        },
        "tags": [],
        "id": "eb49e8bc"
      },
      "outputs": [],
      "source": [
        "import catboost\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "n_folds = 2\n",
        "repeats = 30\n",
        "sample_size = 200000 # 150 000 < 190 000 < 200 000 > 210 000 > 250 000\n",
        "\n",
        "MAX_ITER = 15000\n",
        "PATIENCE = 1000\n",
        "DISPLAY_FREQ = 100\n",
        "\n",
        "modelsCB = []\n",
        "predsCB = []\n",
        "\n",
        "# k_fold = StratifiedKFold(n_splits=n_folds, random_state=42, shuffle=True)\n",
        "k_fold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=repeats, random_state=42)\n",
        "\n",
        "MODEL_PARAMS = {\n",
        "                'random_seed': 1234,\n",
        "                'iterations': MAX_ITER,\n",
        "                'early_stopping_rounds': PATIENCE,\n",
        "#                 'use_best_model': True,\n",
        "                'eval_metric': 'RMSE',\n",
        "                'verbose': 1000,\n",
        "\n",
        "                 'depth': 7, #3,\n",
        "                 'learning_rate': 0.1177165005048142, #0.01177165005048142, #0.2238051305181816,\n",
        "                 'rsm': 0.5,\n",
        "                 'subsample': 0.931,\n",
        "                 'l2_leaf_reg': 69,\n",
        "                 'min_data_in_leaf': 20,\n",
        "                 'random_strength': 0.175,\n",
        "               }\n",
        "\n",
        "catboost_params = {'n_estimators': 500,\n",
        "                   'learning_rate': 0.03,\n",
        "                   'one_hot_max_size': 12,\n",
        "                   'depth': 4,\n",
        "                   'l2_leaf_reg': 0.014,\n",
        "                   'colsample_bylevel': 0.06,\n",
        "                   'min_data_in_leaf': 12,\n",
        "                   'boosting_type': 'Plain',\n",
        "                   'bootstrap_type': 'Bernoulli',\n",
        "                   'verbose': False}\n",
        "\n",
        "\n",
        "# for train_index, test_index in k_fold.split(X, y):\n",
        "#     X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
        "#     y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "# #     model = catboost.CatBoostClassifier(**MODEL_PARAMS)\n",
        "#     model = catboost.CatBoostRegressor(**MODEL_PARAMS)\n",
        "\n",
        "#     model.fit(X=X_train, y=y_train,\n",
        "#           eval_set=[(X_valid, y_valid)],\n",
        "#           early_stopping_rounds = PATIENCE,\n",
        "# #           metric_period = DISPLAY_FREQ\n",
        "#          )\n",
        "#     modelsCB.append(model)\n",
        "#     predsCB.append(model.predict(X_test))\n",
        "\n",
        "for i in range(repeats):\n",
        "    sample = undersample.sample(n=sample_size)\n",
        "    merged = pd.concat([oversample,sample])\n",
        "    X = merged.drop('Class', axis=1)\n",
        "    y = merged['Class']\n",
        "    model = catboost.CatBoostRegressor(**catboost_params)\n",
        "    model.fit(X,y,\n",
        "             early_stopping_rounds = PATIENCE,)\n",
        "    modelsCB.append(model)\n",
        "    predsCB.append(model.predict(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e561f80b",
      "metadata": {
        "papermill": {
          "duration": 0.015246,
          "end_time": "2023-01-30T12:15:50.093238",
          "exception": false,
          "start_time": "2023-01-30T12:15:50.077992",
          "status": "completed"
        },
        "tags": [],
        "id": "e561f80b"
      },
      "source": [
        "**CatBoost classifier model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "598ecd79",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:15:50.127314Z",
          "iopub.status.busy": "2023-01-30T12:15:50.126297Z",
          "iopub.status.idle": "2023-01-30T12:15:50.132457Z",
          "shell.execute_reply": "2023-01-30T12:15:50.131691Z"
        },
        "papermill": {
          "duration": 0.02523,
          "end_time": "2023-01-30T12:15:50.134684",
          "exception": false,
          "start_time": "2023-01-30T12:15:50.109454",
          "status": "completed"
        },
        "tags": [],
        "id": "598ecd79"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# import catboost\n",
        "# from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
        "# from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# def catboost_cl_objective(trial):\n",
        "#     learning_rate = trial.suggest_float('learning_rate', 0, 0.3)\n",
        "#     depth = trial.suggest_int('depth', 3, 10)\n",
        "# #     n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
        "# #     subsample = trial.suggest_float('subsample', 0, 1)\n",
        "# #     l2_leaf_reg = trial.suggest_int('l2_leaf_reg', 1, 100)\n",
        "# #     min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 100)\n",
        "\n",
        "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "\n",
        "#     model = catboost.CatBoostClassifier(\n",
        "#                 random_seed = 1234,\n",
        "# #                 iterations = 5000,\n",
        "# #                 early_stopping_rounds = 1000,\n",
        "# #                 use_best_model = True,\n",
        "#                 eval_metric = 'AUC',\n",
        "#                 verbose = 5000,\n",
        "\n",
        "#                  depth = depth,\n",
        "#                  learning_rate = learning_rate,\n",
        "#                  rsm = 0.5,\n",
        "#                  subsample = 0.931,\n",
        "#                  l2_leaf_reg = 69,\n",
        "#                  min_data_in_leaf = 20,\n",
        "#                  random_strength = 0.175,\n",
        "#     )\n",
        "\n",
        "#     model.fit(X_train, y_train)\n",
        "\n",
        "# #     kf = KFold(n_splits= 5)\n",
        "# #     cv_score = cross_val_score(model, X, y, scoring= 'roc_auc', cv= kf)\n",
        "#     return roc_auc_score(y_test, model.predict(X_test))\n",
        "\n",
        "# study = optuna.create_study(direction= 'maximize')\n",
        "# study.optimize(catboost_cl_objective, n_trials= 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cad479cc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:15:50.167661Z",
          "iopub.status.busy": "2023-01-30T12:15:50.167193Z",
          "iopub.status.idle": "2023-01-30T12:15:50.172306Z",
          "shell.execute_reply": "2023-01-30T12:15:50.171165Z"
        },
        "papermill": {
          "duration": 0.024664,
          "end_time": "2023-01-30T12:15:50.174660",
          "exception": false,
          "start_time": "2023-01-30T12:15:50.149996",
          "status": "completed"
        },
        "tags": [],
        "id": "cad479cc"
      },
      "outputs": [],
      "source": [
        "# study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22bc85ab",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:15:50.207637Z",
          "iopub.status.busy": "2023-01-30T12:15:50.207198Z",
          "iopub.status.idle": "2023-01-30T12:20:59.472117Z",
          "shell.execute_reply": "2023-01-30T12:20:59.470792Z"
        },
        "papermill": {
          "duration": 309.285044,
          "end_time": "2023-01-30T12:20:59.475317",
          "exception": false,
          "start_time": "2023-01-30T12:15:50.190273",
          "status": "completed"
        },
        "tags": [],
        "id": "22bc85ab"
      },
      "outputs": [],
      "source": [
        "MAX_ITER = 15000\n",
        "PATIENCE = 1000\n",
        "DISPLAY_FREQ = 100\n",
        "\n",
        "modelsCBC = []\n",
        "predsCBC = []\n",
        "\n",
        "# k_fold = StratifiedKFold(n_splits=n_folds, random_state=42, shuffle=True)\n",
        "k_fold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=repeats, random_state=42)\n",
        "\n",
        "MODEL_PARAMS = {\n",
        "                'random_seed': 1234,\n",
        "                'iterations': MAX_ITER,\n",
        "                'early_stopping_rounds': PATIENCE,\n",
        "#                 'use_best_model': True,\n",
        "                'eval_metric': 'AUC',\n",
        "#                 'eval_metric': 'RMSE',\n",
        "                'verbose': 1000,\n",
        "\n",
        "                 'depth': 6, #3,\n",
        "                 'learning_rate': 0.08989547995455076, #0.2238051305181816,\n",
        "                 'rsm': 0.5,\n",
        "                 'subsample': 0.931,\n",
        "                 'l2_leaf_reg': 69,\n",
        "                 'min_data_in_leaf': 20,\n",
        "                 'random_strength': 0.175,\n",
        "               }\n",
        "catboost_params = {'n_estimators': 500,\n",
        "                   'learning_rate': 0.03,\n",
        "                   'one_hot_max_size': 12,\n",
        "                   'depth': 4,\n",
        "                   'l2_leaf_reg': 0.014,\n",
        "                   'colsample_bylevel': 0.06,\n",
        "                   'min_data_in_leaf': 12,\n",
        "                   'boosting_type': 'Plain',\n",
        "                   'bootstrap_type': 'Bernoulli',\n",
        "                   'verbose': False}\n",
        "\n",
        "# for train_index, test_index in k_fold.split(X, y):\n",
        "#     X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
        "#     y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "#     model = catboost.CatBoostClassifier(**MODEL_PARAMS)\n",
        "# #     model = catboost.CatBoostRegressor(**MODEL_PARAMS)\n",
        "\n",
        "#     model.fit(X=X_train, y=y_train,\n",
        "#           eval_set=[(X_valid, y_valid)],\n",
        "#           early_stopping_rounds = PATIENCE,\n",
        "# #           metric_period = DISPLAY_FREQ\n",
        "#          )\n",
        "#     modelsCBC.append(model)\n",
        "#     predsCBC.append(model.predict_proba(X_test)[:, 1])\n",
        "\n",
        "for i in range(repeats):\n",
        "    sample = undersample.sample(n=sample_size)\n",
        "    merged = pd.concat([oversample,sample])\n",
        "    X = merged.drop('Class', axis=1)\n",
        "    y = merged['Class']\n",
        "    model = catboost.CatBoostClassifier(**catboost_params)\n",
        "    model.fit(X,y,\n",
        "             early_stopping_rounds = PATIENCE,)\n",
        "    modelsCBC.append(model)\n",
        "    predsCBC.append(model.predict_proba(X_test)[:, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c332ff2b",
      "metadata": {
        "papermill": {
          "duration": 0.015317,
          "end_time": "2023-01-30T12:20:59.506714",
          "exception": false,
          "start_time": "2023-01-30T12:20:59.491397",
          "status": "completed"
        },
        "tags": [],
        "id": "c332ff2b"
      },
      "source": [
        "**XGBoost regression model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e02abb87",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:20:59.539853Z",
          "iopub.status.busy": "2023-01-30T12:20:59.539451Z",
          "iopub.status.idle": "2023-01-30T12:20:59.545700Z",
          "shell.execute_reply": "2023-01-30T12:20:59.544435Z"
        },
        "papermill": {
          "duration": 0.025518,
          "end_time": "2023-01-30T12:20:59.548033",
          "exception": false,
          "start_time": "2023-01-30T12:20:59.522515",
          "status": "completed"
        },
        "tags": [],
        "id": "e02abb87"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# import catboost\n",
        "# from xgboost import XGBClassifier, XGBRegressor\n",
        "# from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
        "# from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# def xgboost_objective(trial):\n",
        "#     learning_rate = trial.suggest_float('learning_rate', 0, 0.3)\n",
        "#     depth = trial.suggest_int('depth', 3, 10)\n",
        "# #     n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
        "# #     subsample = trial.suggest_float('subsample', 0, 1)\n",
        "# #     l2_leaf_reg = trial.suggest_int('l2_leaf_reg', 1, 100)\n",
        "# #     min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 100)\n",
        "\n",
        "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "\n",
        "#     model = XGBRegressor(\n",
        "#                 n_estimators  = 2145,\n",
        "#               min_child_weight = 96,\n",
        "#               max_depth = depth,\n",
        "#               learning_rate = learning_rate,\n",
        "#               subsample = 0.95,\n",
        "#               colsample_bytree = 0.95,\n",
        "#               reg_lambda = 1.50,\n",
        "#               reg_alpha = 1.50,\n",
        "#               gamma = 1.50,\n",
        "#               max_bin = 512,\n",
        "#               random_state = 42,\n",
        "# #               'objective'        : 'binary:logistic',\n",
        "# #               early_stopping_rounds = 200,\n",
        "#               tree_method = 'hist',\n",
        "#               eval_metric = 'rmse',\n",
        "#     )\n",
        "\n",
        "#     model.fit(X_train, y_train)\n",
        "\n",
        "# #     kf = KFold(n_splits= 5)\n",
        "# #     cv_score = cross_val_score(model, X, y, scoring= 'roc_auc', cv= kf)\n",
        "#     return roc_auc_score(y_test, model.predict(X_test))\n",
        "\n",
        "# study = optuna.create_study(direction= 'maximize')\n",
        "# study.optimize(xgboost_objective, n_trials= 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b93962a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:20:59.582170Z",
          "iopub.status.busy": "2023-01-30T12:20:59.581745Z",
          "iopub.status.idle": "2023-01-30T12:20:59.586552Z",
          "shell.execute_reply": "2023-01-30T12:20:59.585693Z"
        },
        "papermill": {
          "duration": 0.0242,
          "end_time": "2023-01-30T12:20:59.588681",
          "exception": false,
          "start_time": "2023-01-30T12:20:59.564481",
          "status": "completed"
        },
        "tags": [],
        "id": "1b93962a"
      },
      "outputs": [],
      "source": [
        "# study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a112fdd8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:20:59.622427Z",
          "iopub.status.busy": "2023-01-30T12:20:59.621583Z",
          "iopub.status.idle": "2023-01-30T12:38:03.156293Z",
          "shell.execute_reply": "2023-01-30T12:38:03.154698Z"
        },
        "papermill": {
          "duration": 1023.555065,
          "end_time": "2023-01-30T12:38:03.159532",
          "exception": false,
          "start_time": "2023-01-30T12:20:59.604467",
          "status": "completed"
        },
        "tags": [],
        "id": "a112fdd8"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "\n",
        "# k_fold = StratifiedKFold(n_splits=n_folds, random_state=42, shuffle=True)\n",
        "k_fold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=repeats, random_state=42)\n",
        "\n",
        "modelsXB = []\n",
        "predsXB = []\n",
        "\n",
        "PATIENCE = 200\n",
        "\n",
        "# MODEL_PARAMS = {       'n_estimators': 5000,\n",
        "#                        'learning_rate': 0.04625397031701272, #0.04625397031701272, 0.06733333333333334\n",
        "#                        'max_depth': 3, #3, 29\n",
        "#                        'colsample_bytree': 0.9, #0.12954517333371557, #0.9, #0.9, 0.99\n",
        "#                        'subsample': 1, #0.7426054009856451, #1, #1, 0.99\n",
        "# #                        'min_child_weight': 12, #\n",
        "# #                        'gamma': 0.11888888888888888, #\n",
        "#                        'reg_lambda': 20, #55, #20,\n",
        "# #                        'eval_metric': 'auc',\n",
        "#                        'eval_metric': 'rmse',\n",
        "#                        'early_stopping_rounds': PATIENCE,\n",
        "# #                        'tree_method': 'gpu_hist',\n",
        "#                        'seed': 1\n",
        "# }\n",
        "\n",
        "MODEL_PARAMS = {'n_estimators'     : 2145,\n",
        "              'min_child_weight' : 96,\n",
        "              'max_depth'        : 8, #7,\n",
        "              'learning_rate'    : 0.04791309460309468, #0.18,\n",
        "              'subsample'        : 0.95,\n",
        "              'colsample_bytree' : 0.95,\n",
        "              'reg_lambda'       : 1.50,\n",
        "              'reg_alpha'        : 1.50,\n",
        "              'gamma'            : 1.50,\n",
        "              'max_bin'          : 512,\n",
        "              'random_state'     : 42,\n",
        "#               'objective'        : 'binary:logistic',\n",
        "#               'early_stopping_rounds': PATIENCE,\n",
        "              'tree_method'      : 'hist',\n",
        "              'eval_metric'      : 'rmse', #'auc'\n",
        "             }\n",
        "\n",
        "xgb_params = {'n_estimators'     : 2000,\n",
        "              'min_child_weight' : 96,\n",
        "              'max_depth'        : 7,\n",
        "              'learning_rate'    : 0.18,\n",
        "              'subsample'        : 0.95,\n",
        "              'colsample_bytree' : 0.95,\n",
        "              'reg_lambda'       : 1.50,\n",
        "              'reg_alpha'        : 1.50,\n",
        "              'gamma'            : 1.50,\n",
        "              'max_bin'          : 512,\n",
        "              'random_state'     : 42,\n",
        "              'objective'        : 'binary:logistic',\n",
        "              'tree_method'      : 'hist',\n",
        "              'eval_metric'      : 'rmse', #'auc'\n",
        "             }\n",
        "\n",
        "# for train_index, test_index in k_fold.split(X, y):\n",
        "#     X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
        "#     y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "# #     model = XGBClassifier(**MODEL_PARAMS)\n",
        "#     model = XGBRegressor(**MODEL_PARAMS)\n",
        "\n",
        "#     model.fit(X=X_train, y=y_train,\n",
        "#           eval_set=[(X_valid, y_valid)],\n",
        "# #           early_stopping_rounds = PATIENCE,\n",
        "#           verbose = 100\n",
        "#          )\n",
        "#     modelsXB.append(model)\n",
        "#     predsXB.append(model.predict(X_test))\n",
        "\n",
        "for i in range(repeats):\n",
        "    sample = undersample.sample(n=sample_size)\n",
        "    merged = pd.concat([oversample,sample])\n",
        "    X = merged.drop('Class', axis=1)\n",
        "    y = merged['Class']\n",
        "    model = XGBRegressor(**xgb_params)\n",
        "    model.fit(X,y,verbose = 100,\n",
        "#              early_stopping_rounds = PATIENCE,\n",
        "             )\n",
        "    modelsXB.append(model)\n",
        "    predsXB.append(model.predict(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2242f1a8",
      "metadata": {
        "papermill": {
          "duration": 0.023707,
          "end_time": "2023-01-30T12:38:03.208067",
          "exception": false,
          "start_time": "2023-01-30T12:38:03.184360",
          "status": "completed"
        },
        "tags": [],
        "id": "2242f1a8"
      },
      "source": [
        "**XGBoost classifier model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9087cbe",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:38:03.246008Z",
          "iopub.status.busy": "2023-01-30T12:38:03.245251Z",
          "iopub.status.idle": "2023-01-30T12:38:03.252184Z",
          "shell.execute_reply": "2023-01-30T12:38:03.250646Z"
        },
        "papermill": {
          "duration": 0.03609,
          "end_time": "2023-01-30T12:38:03.262480",
          "exception": false,
          "start_time": "2023-01-30T12:38:03.226390",
          "status": "completed"
        },
        "tags": [],
        "id": "a9087cbe"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# import catboost\n",
        "# from xgboost import XGBClassifier, XGBRegressor\n",
        "# from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
        "# from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# def xgboost_cl_objective(trial):\n",
        "#     learning_rate = trial.suggest_float('learning_rate', 0, 0.3)\n",
        "#     depth = trial.suggest_int('depth', 3, 10)\n",
        "# #     n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
        "# #     subsample = trial.suggest_float('subsample', 0, 1)\n",
        "# #     l2_leaf_reg = trial.suggest_int('l2_leaf_reg', 1, 100)\n",
        "# #     min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 100)\n",
        "\n",
        "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "\n",
        "#     model = XGBClassifier(\n",
        "#                 n_estimators  = 2145,\n",
        "#               min_child_weight = 96,\n",
        "#               max_depth = depth,\n",
        "#               learning_rate = learning_rate,\n",
        "#               subsample = 0.95,\n",
        "#               colsample_bytree = 0.95,\n",
        "#               reg_lambda = 1.50,\n",
        "#               reg_alpha = 1.50,\n",
        "#               gamma = 1.50,\n",
        "#               max_bin = 512,\n",
        "#               random_state = 42,\n",
        "# #               'objective'        : 'binary:logistic',\n",
        "# #               early_stopping_rounds = 200,\n",
        "#               tree_method = 'hist',\n",
        "#               eval_metric = 'auc',\n",
        "#     )\n",
        "\n",
        "#     model.fit(X_train, y_train)\n",
        "\n",
        "# #     kf = KFold(n_splits= 5)\n",
        "# #     cv_score = cross_val_score(model, X, y, scoring= 'roc_auc', cv= kf)\n",
        "#     return roc_auc_score(y_test, model.predict(X_test))\n",
        "\n",
        "# study = optuna.create_study(direction= 'maximize')\n",
        "# study.optimize(xgboost_cl_objective, n_trials= 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d49331f1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:38:03.296669Z",
          "iopub.status.busy": "2023-01-30T12:38:03.295813Z",
          "iopub.status.idle": "2023-01-30T12:38:03.301149Z",
          "shell.execute_reply": "2023-01-30T12:38:03.300110Z"
        },
        "papermill": {
          "duration": 0.025438,
          "end_time": "2023-01-30T12:38:03.303665",
          "exception": false,
          "start_time": "2023-01-30T12:38:03.278227",
          "status": "completed"
        },
        "tags": [],
        "id": "d49331f1"
      },
      "outputs": [],
      "source": [
        "# study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a91ef31",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:38:03.337366Z",
          "iopub.status.busy": "2023-01-30T12:38:03.336989Z",
          "iopub.status.idle": "2023-01-30T12:55:17.201650Z",
          "shell.execute_reply": "2023-01-30T12:55:17.200458Z"
        },
        "papermill": {
          "duration": 1033.884983,
          "end_time": "2023-01-30T12:55:17.204712",
          "exception": false,
          "start_time": "2023-01-30T12:38:03.319729",
          "status": "completed"
        },
        "tags": [],
        "id": "9a91ef31"
      },
      "outputs": [],
      "source": [
        "k_fold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=repeats, random_state=42)\n",
        "\n",
        "modelsXBC = []\n",
        "predsXBC = []\n",
        "\n",
        "PATIENCE = 200\n",
        "\n",
        "# MODEL_PARAMS = {       'n_estimators': 5000,\n",
        "#                        'learning_rate': 0.04625397031701272, #0.02910875107189472, #0.04625397031701272, 0.06733333333333334\n",
        "#                        'max_depth': 3, #4, #3, 29\n",
        "#                        'colsample_bytree': 0.9, #0.11912735505392935, #0.9, #0.9, 0.99\n",
        "#                        'subsample': 1, #0.7605555695727094, # 1, #1, 0.99\n",
        "# #                        'min_child_weight': 12, #\n",
        "# #                        'gamma': 0.11888888888888888, #\n",
        "#                        'reg_lambda': 20, #17, #20,\n",
        "#                        'eval_metric': 'auc',\n",
        "# #                        'eval_metric': 'rmse',\n",
        "#                        'early_stopping_rounds': PATIENCE,\n",
        "# #                        'tree_method': 'gpu_hist',\n",
        "#                        'seed': 1\n",
        "# }\n",
        "\n",
        "MODEL_PARAMS = {'n_estimators'     : 2145,\n",
        "              'min_child_weight' : 96,\n",
        "              'max_depth'        : 5, #7,\n",
        "              'learning_rate'    : 0.25242368703215484, #0.18,\n",
        "              'subsample'        : 0.95,\n",
        "              'colsample_bytree' : 0.95,\n",
        "              'reg_lambda'       : 1.50,\n",
        "              'reg_alpha'        : 1.50,\n",
        "              'gamma'            : 1.50,\n",
        "              'max_bin'          : 512,\n",
        "              'random_state'     : 42,\n",
        "              'objective'        : 'binary:logistic',\n",
        "#               'early_stopping_rounds': PATIENCE,\n",
        "              'tree_method'      : 'hist',\n",
        "              'eval_metric'      : 'auc'\n",
        "             }\n",
        "\n",
        "xgb_params = {'n_estimators'     : 2000,\n",
        "              'min_child_weight' : 96,\n",
        "              'max_depth'        : 7,\n",
        "              'learning_rate'    : 0.18,\n",
        "              'subsample'        : 0.95,\n",
        "              'colsample_bytree' : 0.95,\n",
        "              'reg_lambda'       : 1.50,\n",
        "              'reg_alpha'        : 1.50,\n",
        "              'gamma'            : 1.50,\n",
        "              'max_bin'          : 512,\n",
        "              'random_state'     : 42,\n",
        "              'objective'        : 'binary:logistic',\n",
        "              'tree_method'      : 'hist',\n",
        "              'eval_metric'      : 'auc'\n",
        "             }\n",
        "\n",
        "# for train_index, test_index in k_fold.split(X, y):\n",
        "#     X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
        "#     y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "#     model = XGBClassifier(**MODEL_PARAMS)\n",
        "# #     model = XGBRegressor(**MODEL_PARAMS)\n",
        "\n",
        "#     model.fit(X=X_train, y=y_train,\n",
        "#           eval_set=[(X_valid, y_valid)],\n",
        "# #           early_stopping_rounds = PATIENCE,\n",
        "#           verbose = 100\n",
        "#          )\n",
        "#     modelsXBC.append(model)\n",
        "#     predsXBC.append(model.predict_proba(X_test)[:, 1])\n",
        "\n",
        "for i in range(repeats):\n",
        "    sample = undersample.sample(n=sample_size)\n",
        "    merged = pd.concat([oversample,sample])\n",
        "    X = merged.drop('Class', axis=1)\n",
        "    y = merged['Class']\n",
        "    model = XGBClassifier(**xgb_params)\n",
        "    model.fit(X,y,verbose = 100,\n",
        "#              early_stopping_rounds = PATIENCE,\n",
        "             )\n",
        "    modelsXBC.append(model)\n",
        "    predsXBC.append(model.predict_proba(X_test)[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "287b8028",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:55:17.240930Z",
          "iopub.status.busy": "2023-01-30T12:55:17.240522Z",
          "iopub.status.idle": "2023-01-30T12:57:07.153682Z",
          "shell.execute_reply": "2023-01-30T12:57:07.152705Z"
        },
        "papermill": {
          "duration": 109.932973,
          "end_time": "2023-01-30T12:57:07.156344",
          "exception": false,
          "start_time": "2023-01-30T12:55:17.223371",
          "status": "completed"
        },
        "tags": [],
        "id": "287b8028",
        "outputId": "94d4d975-3b5a-45e9-b377-537bfa2a7943"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type='text/css'>\n",
              ".datatable table.frame { margin-bottom: 0; }\n",
              ".datatable table.frame thead { border-bottom: none; }\n",
              ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
              ".datatable .bool    { background: #DDDD99; }\n",
              ".datatable .object  { background: #565656; }\n",
              ".datatable .int     { background: #5D9E5D; }\n",
              ".datatable .float   { background: #4040CC; }\n",
              ".datatable .str     { background: #CC4040; }\n",
              ".datatable .time    { background: #40CC40; }\n",
              ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
              ".datatable .frame tbody td { text-align: left; }\n",
              ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
              ".datatable th:nth-child(2) { padding-left: 12px; }\n",
              ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
              ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
              ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
              ".datatable .sp {  opacity: 0.25;}\n",
              ".datatable .footer { font-size: 9px; }\n",
              ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgbm\n",
        "\n",
        "k_fold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=repeats, random_state=42)\n",
        "\n",
        "modelsLBC = []\n",
        "predsLBC = []\n",
        "\n",
        "# PATIENCE = 200\n",
        "\n",
        "params={\n",
        "             'objective': 'binary',\n",
        "             'metric': 'auc',\n",
        "             'lambda_l1': 1.0050418664783436e-08,\n",
        "             'lambda_l2': 9.938606206413121,\n",
        "             'scale_pos_weight': 1, #param could be ignored\n",
        "             'num_leaves': 44,\n",
        "             'feature_fraction': 0.8247273276668773,\n",
        "             'bagging_fraction': 0.5842711778104962,\n",
        "             'bagging_freq': 6,\n",
        "             'min_data_in_leaf': 134,\n",
        "             'min_child_samples': 70,\n",
        "             'max_depth': 8,\n",
        "             'num_iterations': 400,\n",
        "             'learning_rate':0.05}\n",
        "\n",
        "lgbm_params = {'n_estimators': 500,\n",
        "                 'num_rounds': 274,\n",
        "                 'learning_rate': 0.1,\n",
        "                 'num_leaves': 195,\n",
        "                 'max_depth': 9,\n",
        "                 'min_data_in_leaf': 46,\n",
        "                 'lambda_l1': 0.01,\n",
        "                 'lambda_l2': 0.6,\n",
        "                 'min_gain_to_split': 1.42,\n",
        "                 'bagging_fraction': 0.45,\n",
        "                 'feature_fraction': 0.3,\n",
        "                 'verbose':-1}\n",
        "\n",
        "# for train_index, test_index in k_fold.split(X, y):\n",
        "#     X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
        "#     y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "#     model = lgbm.LGBMClassifier(**params)\n",
        "# #     model = lgbm.LGBMRegressor(**MODEL_PARAMS)\n",
        "\n",
        "#     model.fit(X=X_train, y=y_train,\n",
        "#           eval_set=[(X_valid, y_valid)],\n",
        "#           early_stopping_rounds = 50,\n",
        "#           verbose = 100\n",
        "#          )\n",
        "#     modelsLBC.append(model)\n",
        "#     predsLBC.append(model.predict_proba(X_test)[:, 1])\n",
        "\n",
        "for i in range(repeats):\n",
        "    sample = undersample.sample(n=sample_size)\n",
        "    merged = pd.concat([oversample,sample])\n",
        "    X = merged.drop('Class', axis=1)\n",
        "    y = merged['Class']\n",
        "    model = lgbm.LGBMClassifier(**lgbm_params)\n",
        "    model.fit(X=X,y=y,verbose = 100,\n",
        "#              early_stopping_rounds = PATIENCE,\n",
        "             )\n",
        "    modelsLBC.append(model)\n",
        "    predsLBC.append(model.predict_proba(X_test)[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "823c3c20",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:57:07.196552Z",
          "iopub.status.busy": "2023-01-30T12:57:07.196149Z",
          "iopub.status.idle": "2023-01-30T12:58:10.859747Z",
          "shell.execute_reply": "2023-01-30T12:58:10.858667Z"
        },
        "papermill": {
          "duration": 63.686294,
          "end_time": "2023-01-30T12:58:10.862694",
          "exception": false,
          "start_time": "2023-01-30T12:57:07.176400",
          "status": "completed"
        },
        "tags": [],
        "id": "823c3c20",
        "outputId": "17671e58-9ca5-42d7-975c-3843b300ac59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.45, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45\n",
            "[LightGBM] [Warning] num_iterations is set=274, num_rounds=274 will be ignored. Current value: num_iterations=274\n",
            "[LightGBM] [Warning] min_gain_to_split is set=1.42, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.42\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgbm\n",
        "\n",
        "k_fold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=repeats, random_state=42)\n",
        "\n",
        "modelsLB = []\n",
        "predsLB = []\n",
        "\n",
        "# PATIENCE = 200\n",
        "\n",
        "params={\n",
        "#              'objective': 'binary',\n",
        "             'metric': 'rmse',\n",
        "             'lambda_l1': 1.0050418664783436e-08,\n",
        "             'lambda_l2': 9.938606206413121,\n",
        "             'scale_pos_weight': 1, #param could be ignored\n",
        "             'num_leaves': 44,\n",
        "             'feature_fraction': 0.8247273276668773,\n",
        "             'bagging_fraction': 0.5842711778104962,\n",
        "             'bagging_freq': 6,\n",
        "             'min_data_in_leaf': 134,\n",
        "             'min_child_samples': 70,\n",
        "             'max_depth': 8,\n",
        "             'num_iterations': 400,\n",
        "             'learning_rate':0.05}\n",
        "\n",
        "lgbm_params = {'n_estimators': 500,\n",
        "                 'num_rounds': 274,\n",
        "                 'learning_rate': 0.1,\n",
        "                 'num_leaves': 195,\n",
        "                 'max_depth': 9,\n",
        "                 'min_data_in_leaf': 46,\n",
        "                 'lambda_l1': 0.01,\n",
        "                 'lambda_l2': 0.6,\n",
        "                 'min_gain_to_split': 1.42,\n",
        "                 'bagging_fraction': 0.45,\n",
        "                 'feature_fraction': 0.3,\n",
        "                 'verbose':-1}\n",
        "\n",
        "# for train_index, test_index in k_fold.split(X, y):\n",
        "#     X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
        "#     y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "# #     model = lgbm.LGBMClassifier(**MODEL_PARAMS)\n",
        "#     model = lgbm.LGBMRegressor(**params)\n",
        "\n",
        "#     model.fit(X=X_train, y=y_train,\n",
        "#           eval_set=[(X_valid, y_valid)],\n",
        "#           early_stopping_rounds = 50,\n",
        "#           verbose = 100\n",
        "#          )\n",
        "#     modelsLB.append(model)\n",
        "#     predsLB.append(model.predict(X_test))\n",
        "\n",
        "for i in range(repeats):\n",
        "    sample = undersample.sample(n=sample_size)\n",
        "    merged = pd.concat([oversample,sample])\n",
        "    X = merged.drop('Class', axis=1)\n",
        "    y = merged['Class']\n",
        "    model = lgbm.LGBMRegressor(**lgbm_params)\n",
        "    model.fit(X=X,y=y,verbose = 100,\n",
        "#              early_stopping_rounds = PATIENCE,\n",
        "             )\n",
        "    modelsLB.append(model)\n",
        "    predsLB.append(model.predict(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab346107",
      "metadata": {
        "papermill": {
          "duration": 0.019737,
          "end_time": "2023-01-30T12:58:10.904591",
          "exception": false,
          "start_time": "2023-01-30T12:58:10.884854",
          "status": "completed"
        },
        "tags": [],
        "id": "ab346107"
      },
      "source": [
        "**Lasso linear regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da75deeb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:58:10.947460Z",
          "iopub.status.busy": "2023-01-30T12:58:10.947061Z",
          "iopub.status.idle": "2023-01-30T12:58:34.367445Z",
          "shell.execute_reply": "2023-01-30T12:58:34.365776Z"
        },
        "papermill": {
          "duration": 23.447353,
          "end_time": "2023-01-30T12:58:34.372220",
          "exception": false,
          "start_time": "2023-01-30T12:58:10.924867",
          "status": "completed"
        },
        "tags": [],
        "id": "da75deeb"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LassoCV, Lasso\n",
        "\n",
        "# n_folds = 20\n",
        "# k_fold = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=2*repeats, random_state=42) # 20\n",
        "\n",
        "modelsLR = []\n",
        "predsLR = []\n",
        "\n",
        "MODEL_PARAMS = {\n",
        "                       'precompute': \"auto\",\n",
        "                       'fit_intercept': True,\n",
        "                       'normalize': False,\n",
        "                       'max_iter': 10000,\n",
        "                       'verbose': False,\n",
        "                       'eps': 0.000001, #1e-04, #0.007267206407101401, #1e-04,\n",
        "                       'cv': 5, #6, #5,\n",
        "                       'n_alphas': 1000,\n",
        "                       'n_jobs': 8,\n",
        "                       'tol': 0.0001\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# for train_index, test_index in k_fold.split(X, y):\n",
        "#     X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
        "#     y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "#     model = LassoCV(**MODEL_PARAMS)\n",
        "\n",
        "#     model.fit(X=X_train, y=y_train,\n",
        "# #           eval_set=[(X_valid, y_valid)],\n",
        "#          )\n",
        "\n",
        "#     modelsLR.append(model)\n",
        "#     predsLR.append(model.predict(X_test))\n",
        "\n",
        "for i in range(repeats):\n",
        "    sample = undersample.sample(n=sample_size)\n",
        "    merged = pd.concat([oversample,sample])\n",
        "    X = merged.drop('Class', axis=1)\n",
        "    y = merged['Class']\n",
        "    model = Lasso(alpha=0.001)\n",
        "    model.fit(X,y,\n",
        "#              early_stopping_rounds = PATIENCE,\n",
        "             )\n",
        "    modelsLR.append(model)\n",
        "    predsLR.append(model.predict(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae784d89",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:58:34.505459Z",
          "iopub.status.busy": "2023-01-30T12:58:34.505081Z",
          "iopub.status.idle": "2023-01-30T12:58:34.521356Z",
          "shell.execute_reply": "2023-01-30T12:58:34.520027Z"
        },
        "papermill": {
          "duration": 0.043241,
          "end_time": "2023-01-30T12:58:34.523943",
          "exception": false,
          "start_time": "2023-01-30T12:58:34.480702",
          "status": "completed"
        },
        "tags": [],
        "id": "ae784d89"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "def coef_objective(trial):\n",
        "    a = trial.suggest_float('a', 0, 1)\n",
        "    b = trial.suggest_float('b', 0, 1)\n",
        "    c = trial.suggest_float('c', 0, 1)\n",
        "    d = trial.suggest_float('d', 0, 1)\n",
        "    e = trial.suggest_float('e', 0, 1)\n",
        "    f = trial.suggest_float('f', 0, 1)\n",
        "#     g = trial.suggest_float('g', 0, 1)\n",
        "\n",
        "#     merged = pd.concat([oversample1,undersample1])\n",
        "#     X = merged.drop('Class', axis=1)\n",
        "#     y = merged['Class']\n",
        "\n",
        "#     X = X1\n",
        "#     y = y1\n",
        "\n",
        "    preds_eval = []\n",
        "    for model in modelsCB:\n",
        "        preds_eval.append(model.predict(X))\n",
        "\n",
        "    resCB = np.average(np.array(preds_eval),axis=0)\n",
        "\n",
        "    preds_eval = []\n",
        "    for model in modelsXB:\n",
        "        preds_eval.append(model.predict(X))\n",
        "\n",
        "    resXB = np.average(np.array(preds_eval),axis=0)\n",
        "\n",
        "    preds_eval = []\n",
        "    for model in modelsCBC:\n",
        "        preds_eval.append(model.predict_proba(X)[:, 1])\n",
        "\n",
        "    resCBC = np.average(np.array(preds_eval),axis=0)\n",
        "\n",
        "    preds_eval = []\n",
        "    for model in modelsXBC:\n",
        "        preds_eval.append(model.predict_proba(X)[:, 1])\n",
        "\n",
        "    resXBC = np.average(np.array(preds_eval),axis=0)\n",
        "\n",
        "    preds_eval = []\n",
        "    for model in modelsLBC:\n",
        "        preds_eval.append(model.predict_proba(X)[:, 1])\n",
        "\n",
        "    resLBC = np.average(np.array(preds_eval),axis=0)\n",
        "\n",
        "    preds_eval = []\n",
        "    for model in modelsLB:\n",
        "        preds_eval.append(model.predict(X))\n",
        "\n",
        "    resLB = np.average(np.array(preds_eval),axis=0)\n",
        "\n",
        "\n",
        "#     preds_eval = []\n",
        "#     for model in modelsLR:\n",
        "#         preds_eval.append(model.predict(X))\n",
        "\n",
        "#     resLR = np.average(np.array(preds_eval),axis=0)\n",
        "\n",
        "    res = roc_auc_score(y,\n",
        "                        (resCB * a + resXB * b + resCBC * c + resXBC * d + resLBC * e +\n",
        "                         resLB * f )/(a + b + c + d + e + f))\n",
        "\n",
        "    return res\n",
        "\n",
        "study = optuna.create_study(direction= 'maximize')\n",
        "# study.optimize(coef_objective, n_trials= 100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc21b657",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:58:34.570062Z",
          "iopub.status.busy": "2023-01-30T12:58:34.569625Z",
          "iopub.status.idle": "2023-01-30T12:58:34.575013Z",
          "shell.execute_reply": "2023-01-30T12:58:34.573722Z"
        },
        "papermill": {
          "duration": 0.03189,
          "end_time": "2023-01-30T12:58:34.577283",
          "exception": false,
          "start_time": "2023-01-30T12:58:34.545393",
          "status": "completed"
        },
        "tags": [],
        "id": "dc21b657"
      },
      "outputs": [],
      "source": [
        "# study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8a8af4a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:58:34.620838Z",
          "iopub.status.busy": "2023-01-30T12:58:34.620076Z",
          "iopub.status.idle": "2023-01-30T12:58:34.625026Z",
          "shell.execute_reply": "2023-01-30T12:58:34.624201Z"
        },
        "papermill": {
          "duration": 0.029445,
          "end_time": "2023-01-30T12:58:34.627110",
          "exception": false,
          "start_time": "2023-01-30T12:58:34.597665",
          "status": "completed"
        },
        "tags": [],
        "id": "c8a8af4a"
      },
      "outputs": [],
      "source": [
        "# a = study.best_params['a']\n",
        "# b = study.best_params['b']\n",
        "# c = study.best_params['c']\n",
        "# d = study.best_params['d']\n",
        "# e = study.best_params['e']\n",
        "# f = study.best_params['f']\n",
        "# # g = study.best_params['g']\n",
        "\n",
        "# sum_coef = a + b + c + d + e + f\n",
        "# a = a / sum_coef\n",
        "# b = b / sum_coef\n",
        "# c = c / sum_coef\n",
        "# d = d / sum_coef\n",
        "# e = e / sum_coef\n",
        "# f = f / sum_coef\n",
        "# # g = g / sum_coef\n",
        "\n",
        "# a, b, c, d, e, f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f297be30",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:58:34.747861Z",
          "iopub.status.busy": "2023-01-30T12:58:34.747423Z",
          "iopub.status.idle": "2023-01-30T12:58:34.751782Z",
          "shell.execute_reply": "2023-01-30T12:58:34.750660Z"
        },
        "papermill": {
          "duration": 0.105774,
          "end_time": "2023-01-30T12:58:34.754219",
          "exception": false,
          "start_time": "2023-01-30T12:58:34.648445",
          "status": "completed"
        },
        "tags": [],
        "id": "f297be30"
      },
      "outputs": [],
      "source": [
        "# a = 0.3669557354589081\n",
        "# b = 0.337641198537538\n",
        "# c = 0.008900837188394609\n",
        "# d = 0.2447433523478509\n",
        "# e = 0.04175887646730838"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b884c332",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:58:34.799569Z",
          "iopub.status.busy": "2023-01-30T12:58:34.798904Z",
          "iopub.status.idle": "2023-01-30T12:58:34.803264Z",
          "shell.execute_reply": "2023-01-30T12:58:34.802523Z"
        },
        "papermill": {
          "duration": 0.029841,
          "end_time": "2023-01-30T12:58:34.805372",
          "exception": false,
          "start_time": "2023-01-30T12:58:34.775531",
          "status": "completed"
        },
        "tags": [],
        "id": "b884c332"
      },
      "outputs": [],
      "source": [
        "# a = 0.14719373356287416\n",
        "# b = 0.21197835016639707\n",
        "# c = 0.5218752467435989\n",
        "# d = 0.11810079201731347\n",
        "# e = 0.0008518775098164659"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9240a1be",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:58:34.848028Z",
          "iopub.status.busy": "2023-01-30T12:58:34.847379Z",
          "iopub.status.idle": "2023-01-30T12:58:34.852332Z",
          "shell.execute_reply": "2023-01-30T12:58:34.851350Z"
        },
        "papermill": {
          "duration": 0.02908,
          "end_time": "2023-01-30T12:58:34.854716",
          "exception": false,
          "start_time": "2023-01-30T12:58:34.825636",
          "status": "completed"
        },
        "tags": [],
        "id": "9240a1be"
      },
      "outputs": [],
      "source": [
        "# a = 0.013732712049429857\n",
        "# b = 0.11139158723935387\n",
        "# c = 0.7579975888425357\n",
        "# d = 0.11626614433593775\n",
        "# e = 0.0006119675327428372"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52fdc590",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:58:34.900703Z",
          "iopub.status.busy": "2023-01-30T12:58:34.899681Z",
          "iopub.status.idle": "2023-01-30T12:58:34.904897Z",
          "shell.execute_reply": "2023-01-30T12:58:34.903990Z"
        },
        "papermill": {
          "duration": 0.030556,
          "end_time": "2023-01-30T12:58:34.907110",
          "exception": false,
          "start_time": "2023-01-30T12:58:34.876554",
          "status": "completed"
        },
        "tags": [],
        "id": "52fdc590"
      },
      "outputs": [],
      "source": [
        "# a = 0.004924244009922518 + 0.011877491530298148\n",
        "# b = 0.3117566542173961\n",
        "# c = 0.10166065209557595\n",
        "# d = 0.0503241817163487\n",
        "# e = 0.4682759529883892\n",
        "# f = 0.051180823442069395\n",
        "# g = 0 #0.011877491530298148"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "347fdfa5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:58:34.951223Z",
          "iopub.status.busy": "2023-01-30T12:58:34.950193Z",
          "iopub.status.idle": "2023-01-30T12:58:34.955714Z",
          "shell.execute_reply": "2023-01-30T12:58:34.954661Z"
        },
        "papermill": {
          "duration": 0.029954,
          "end_time": "2023-01-30T12:58:34.958061",
          "exception": false,
          "start_time": "2023-01-30T12:58:34.928107",
          "status": "completed"
        },
        "tags": [],
        "id": "347fdfa5"
      },
      "outputs": [],
      "source": [
        "# a = 0.17\n",
        "# b = 0.16\n",
        "# c = 0.17\n",
        "# d = 0.17\n",
        "# e = 0.17\n",
        "# f = 0.16\n",
        "# g = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab72f457",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:58:35.000801Z",
          "iopub.status.busy": "2023-01-30T12:58:34.999998Z",
          "iopub.status.idle": "2023-01-30T12:58:35.008567Z",
          "shell.execute_reply": "2023-01-30T12:58:35.007315Z"
        },
        "papermill": {
          "duration": 0.032968,
          "end_time": "2023-01-30T12:58:35.011413",
          "exception": false,
          "start_time": "2023-01-30T12:58:34.978445",
          "status": "completed"
        },
        "tags": [],
        "id": "ab72f457"
      },
      "outputs": [],
      "source": [
        "# a = 0.15\n",
        "# b = 0.14\n",
        "# c = 0.15\n",
        "# d = 0.14\n",
        "# e = 0.14\n",
        "# f = 0.14\n",
        "# g = 0.14\n",
        "\n",
        "# a = 0.13\n",
        "# b = 0.14\n",
        "# c = 0.2\n",
        "# d = 0.2\n",
        "# e = 0.2\n",
        "# f = 0.13\n",
        "# g = 0\n",
        "\n",
        "# a = 0.2\n",
        "# b = 0.2\n",
        "# c = 0.13\n",
        "# d = 0.14\n",
        "# e = 0.13\n",
        "# f = 0.2\n",
        "# g = 0\n",
        "\n",
        "# a = 0.23\n",
        "# b = 0.23\n",
        "# c = 0.1\n",
        "# d = 0.11\n",
        "# e = 0.1\n",
        "# f = 0.23\n",
        "# g = 0\n",
        "\n",
        "# 0.87022\n",
        "\n",
        "# a = 0.25\n",
        "# b = 0.25\n",
        "# c = 0.08\n",
        "# d = 0.09\n",
        "# e = 0.08\n",
        "# f = 0.25\n",
        "# g = 0\n",
        "\n",
        "# 0.86927\n",
        "\n",
        "# a = 0.22\n",
        "# b = 0.22\n",
        "# c = 0.11\n",
        "# d = 0.12\n",
        "# e = 0.11\n",
        "# f = 0.22\n",
        "# g = 0\n",
        "\n",
        "# 0.86997\n",
        "\n",
        "# a = 0.24\n",
        "# b = 0.24\n",
        "# c = 0.09\n",
        "# d = 0.10\n",
        "# e = 0.09\n",
        "# f = 0.24\n",
        "# g = 0\n",
        "\n",
        "# 0.87044\n",
        "\n",
        "# a = 0.235\n",
        "# b = 0.235\n",
        "# c = 0.095\n",
        "# d = 0.105\n",
        "# e = 0.095\n",
        "# f = 0.235\n",
        "# g = 0\n",
        "\n",
        "# 0.86909\n",
        "\n",
        "# a = 0.238\n",
        "# b = 0.245\n",
        "# c = 0.087\n",
        "# d = 0.105\n",
        "# e = 0.087\n",
        "# f = 0.238\n",
        "# g = 0\n",
        "\n",
        "# 0.86762\n",
        "\n",
        "# a = 0.245\n",
        "# b = 0.238\n",
        "# c = 0.105\n",
        "# d = 0.087\n",
        "# e = 0.087\n",
        "# f = 0.238\n",
        "# g = 0\n",
        "\n",
        "# 0.86741\n",
        "\n",
        "# a = 0.238\n",
        "# b = 0.238\n",
        "# c = 0.092\n",
        "# d = 0.102\n",
        "# e = 0.092\n",
        "# f = 0.238\n",
        "# g = 0\n",
        "\n",
        "# *0.86509\n",
        "\n",
        "# a = 0.241\n",
        "# b = 0.241\n",
        "# c = 0.089\n",
        "# d = 0.099\n",
        "# e = 0.089\n",
        "# f = 0.241\n",
        "# g = 0\n",
        "\n",
        "# *0.86474  0.86686  0.86897\n",
        "\n",
        "a = 0.239\n",
        "b = 0.239\n",
        "c = 0.091\n",
        "d = 0.101\n",
        "e = 0.091\n",
        "f = 0.239\n",
        "g = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e50da8d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:58:35.056096Z",
          "iopub.status.busy": "2023-01-30T12:58:35.055655Z",
          "iopub.status.idle": "2023-01-30T12:58:35.060276Z",
          "shell.execute_reply": "2023-01-30T12:58:35.059262Z"
        },
        "papermill": {
          "duration": 0.029862,
          "end_time": "2023-01-30T12:58:35.062624",
          "exception": false,
          "start_time": "2023-01-30T12:58:35.032762",
          "status": "completed"
        },
        "tags": [],
        "id": "5e50da8d"
      },
      "outputs": [],
      "source": [
        "# a = 0.008764460310928566\n",
        "# b = 0.2964161989525224\n",
        "# c = 0.19274616797827318\n",
        "# d = 0.3180908607731729\n",
        "# e = 0.18358232512438427\n",
        "# f = 0.00039998686071876055\n",
        "# g = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0645fff9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:58:35.106896Z",
          "iopub.status.busy": "2023-01-30T12:58:35.106294Z",
          "iopub.status.idle": "2023-01-30T12:58:35.229080Z",
          "shell.execute_reply": "2023-01-30T12:58:35.227805Z"
        },
        "papermill": {
          "duration": 0.148538,
          "end_time": "2023-01-30T12:58:35.232393",
          "exception": false,
          "start_time": "2023-01-30T12:58:35.083855",
          "status": "completed"
        },
        "tags": [],
        "id": "0645fff9"
      },
      "outputs": [],
      "source": [
        "predCB = np.average(np.array(predsCB),axis=0).clip(0,1)\n",
        "predXB = np.average(np.array(predsXB),axis=0).clip(0,1)\n",
        "predCBC = np.average(np.array(predsCBC),axis=0).clip(0,1)\n",
        "predXBC = np.average(np.array(predsXBC),axis=0).clip(0,1)\n",
        "predLBC = np.average(np.array(predsLBC),axis=0).clip(0,1)\n",
        "predLB = np.average(np.array(predsLB),axis=0).clip(0,1)\n",
        "predLR = np.average(np.array(predsLR),axis=0).clip(0,1)\n",
        "\n",
        "pred = predCB * a + predXB * b + predCBC * c + predXBC * d + predLBC * e + predLB * f + predLR * g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3258f1cb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:58:35.278474Z",
          "iopub.status.busy": "2023-01-30T12:58:35.278021Z",
          "iopub.status.idle": "2023-01-30T12:58:35.568463Z",
          "shell.execute_reply": "2023-01-30T12:58:35.567333Z"
        },
        "papermill": {
          "duration": 0.316866,
          "end_time": "2023-01-30T12:58:35.571007",
          "exception": false,
          "start_time": "2023-01-30T12:58:35.254141",
          "status": "completed"
        },
        "tags": [],
        "id": "3258f1cb",
        "outputId": "487c79e0-b42d-4d3b-c992-72bc0895371e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "pd.Series(predCB).hist(bins=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32882a3f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:58:35.617278Z",
          "iopub.status.busy": "2023-01-30T12:58:35.616881Z",
          "iopub.status.idle": "2023-01-30T12:58:36.045462Z",
          "shell.execute_reply": "2023-01-30T12:58:36.044303Z"
        },
        "papermill": {
          "duration": 0.454867,
          "end_time": "2023-01-30T12:58:36.048217",
          "exception": false,
          "start_time": "2023-01-30T12:58:35.593350",
          "status": "completed"
        },
        "tags": [],
        "id": "32882a3f",
        "outputId": "1049fff2-c2eb-4c6a-9111-de6a90584ce4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD4CAYAAADy46FuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAX0ElEQVR4nO3dfYxddX7f8fenOEu8u4HlIUyRTWoS3CQ8ZNVlytKkjaZ1A84miqkEkrckWFtLVijdbiuqLCRSkbKytKilJNBCZAXKQ9ECJdvafSAbCzrdVuFh2c3ueoEQpgsFB2fJxoTgjSA75Ns/7m+q6/H1mfG9M2MP9/2Srubc7zm/n3/fa2s+c865c52qQpKko/krx3sBkqQTm0EhSepkUEiSOhkUkqROBoUkqdOa472ApXbmmWfWhg0bhh7/ne98hw984ANLt6BVwJ7Hxzj2bc+L8+Uvf/nbVfX9g/a954Jiw4YNPPPMM0OPn56eZmpqaukWtArY8/gYx77teXGS/N+j7fPSkySpk0EhSepkUEiSOhkUkqROBoUkqZNBIUnqtGBQJLk7yetJvjFg379IUknO7KvdmGQmyQtJLu+rX5xkX9t3W5K0+slJHmr1p5Js6BuzLcmL7bFt5G4lScdsMWcU9wCb5xeTnAP8FPBKX+18YCtwQRtzR5KT2u47gR3AxvaYm3M78EZVnQfcCtzc5joduAn4KHAJcFOS046tPUnSqBYMiqr6InBwwK5bgV8C+v9Diy3Ag1X1TlW9BMwAlyQ5Gzilqp6o3n+AcR9wRd+Ye9v2I8CmdrZxObC3qg5W1RvAXgYEliRpeQ31m9lJfg74w6r6WruCNGcd8GTf8/2t9t22Pb8+N+ZVgKqaTfImcEZ/fcCY+evZQe9shYmJCaanp4dpC4DXD77J7Q/sPqJ+0bpTh57zRHfo0KGRXrPVaBx7hvHs255Hd8xBkeT9wK8Alw3aPaBWHfVhxxxerNoF7AKYnJysUX5d//YHdnPLviNflpevHn7OE50fcTA+xrFvex7dMO96+iHgXOBrSV4G1gNfSfJX6f3Uf07fseuB11p9/YA6/WOSrAFOpXep62hzSZJW0DEHRVXtq6qzqmpDVW2g9w39I1X1R8AeYGt7J9O59G5aP11VB4C3klza7j9cA8xd39kDzL2j6Urg8XYf4wvAZUlOazexL2s1SdIKWvDSU5LPAVPAmUn2AzdV1V2Djq2qZ5M8DDwHzALXVdW7bfe19N5BtRZ4tD0A7gLuTzJD70xia5vrYJLPAF9qx/1qVQ26qS5JWkYLBkVVfXyB/RvmPd8J7Bxw3DPAhQPqbwNXHWXuu4G7F1qjJGn5+JvZkqROBoUkqZNBIUnqZFBIkjoZFJKkTgaFJKmTQSFJ6mRQSJI6GRSSpE4GhSSpk0EhSepkUEiSOhkUkqROBoUkqZNBIUnqZFBIkjoZFJKkTgaFJKmTQSFJ6mRQSJI6LRgUSe5O8nqSb/TV/lWS30/y9ST/KcmH+vbdmGQmyQtJLu+rX5xkX9t3W5K0+slJHmr1p5Js6BuzLcmL7bFtqZqWJC3eYs4o7gE2z6vtBS6sqh8D/gC4ESDJ+cBW4II25o4kJ7UxdwI7gI3tMTfnduCNqjoPuBW4uc11OnAT8FHgEuCmJKcde4uSpFEsGBRV9UXg4Lza71TVbHv6JLC+bW8BHqyqd6rqJWAGuCTJ2cApVfVEVRVwH3BF35h72/YjwKZ2tnE5sLeqDlbVG/TCaX5gSZKW2ZolmOMfAQ+17XX0gmPO/lb7btueX58b8ypAVc0meRM4o78+YMxhkuygd7bCxMQE09PTQzczsRauv2j2iPooc57oDh069J7ub5Bx7BnGs297Ht1IQZHkV4BZ4IG50oDDqqM+7JjDi1W7gF0Ak5OTNTU1dfRFL+D2B3Zzy74jX5aXrx5+zhPd9PQ0o7xmq9E49gzj2bc9j27odz21m8s/C1zdLidB76f+c/oOWw+81urrB9QPG5NkDXAqvUtdR5tLkrSChgqKJJuBTwM/V1V/3rdrD7C1vZPpXHo3rZ+uqgPAW0kubfcfrgF2942Ze0fTlcDjLXi+AFyW5LR2E/uyVpMkraAFLz0l+RwwBZyZZD+9dyLdCJwM7G3vcn2yqn6xqp5N8jDwHL1LUtdV1bttqmvpvYNqLfBoewDcBdyfZIbemcRWgKo6mOQzwJfacb9aVYfdVJckLb8Fg6KqPj6gfFfH8TuBnQPqzwAXDqi/DVx1lLnuBu5eaI2SpOXjb2ZLkjoZFJKkTgaFJKmTQSFJ6mRQSJI6GRSSpE4GhSSpk0EhSepkUEiSOhkUkqROBoUkqZNBIUnqZFBIkjoZFJKkTgaFJKmTQSFJ6mRQSJI6GRSSpE4GhSSpk0EhSepkUEiSOi0YFEnuTvJ6km/01U5PsjfJi+3raX37bkwyk+SFJJf31S9Osq/tuy1JWv3kJA+1+lNJNvSN2db+jBeTbFuyriVJi7aYM4p7gM3zajcAj1XVRuCx9pwk5wNbgQvamDuSnNTG3AnsADa2x9yc24E3quo84Fbg5jbX6cBNwEeBS4Cb+gNJkrQyFgyKqvoicHBeeQtwb9u+F7iir/5gVb1TVS8BM8AlSc4GTqmqJ6qqgPvmjZmb6xFgUzvbuBzYW1UHq+oNYC9HBpYkaZmtGXLcRFUdAKiqA0nOavV1wJN9x+1vte+27fn1uTGvtrlmk7wJnNFfHzDmMEl20DtbYWJigunp6SHbgom1cP1Fs0fUR5nzRHfo0KH3dH+DjGPPMJ592/Pohg2Ko8mAWnXUhx1zeLFqF7ALYHJysqamphZc6NHc/sBubtl35Mvy8tXDz3mim56eZpTXbDUax55hPPu259EN+66nb7XLSbSvr7f6fuCcvuPWA6+1+voB9cPGJFkDnErvUtfR5pIkraBhg2IPMPcupG3A7r761vZOpnPp3bR+ul2meivJpe3+wzXzxszNdSXweLuP8QXgsiSntZvYl7WaJGkFLXjpKcnngCngzCT76b0T6bPAw0m2A68AVwFU1bNJHgaeA2aB66rq3TbVtfTeQbUWeLQ9AO4C7k8yQ+9MYmub62CSzwBfasf9alXNv6kuSVpmCwZFVX38KLs2HeX4ncDOAfVngAsH1N+mBc2AfXcDdy+0RknS8vE3syVJnQwKSVIng0KS1MmgkCR1MigkSZ0MCklSJ4NCktTJoJAkdTIoJEmdDApJUieDQpLUyaCQJHUyKCRJnQwKSVIng0KS1MmgkCR1MigkSZ0MCklSJ4NCktTJoJAkdRopKJL88yTPJvlGks8l+d4kpyfZm+TF9vW0vuNvTDKT5IUkl/fVL06yr+27LUla/eQkD7X6U0k2jLJeSdKxGzookqwD/ikwWVUXAicBW4EbgMeqaiPwWHtOkvPb/guAzcAdSU5q090J7AA2tsfmVt8OvFFV5wG3AjcPu15J0nBGvfS0BlibZA3wfuA1YAtwb9t/L3BF294CPFhV71TVS8AMcEmSs4FTquqJqirgvnlj5uZ6BNg0d7YhSVoZQwdFVf0h8K+BV4ADwJtV9TvARFUdaMccAM5qQ9YBr/ZNsb/V1rXt+fXDxlTVLPAmcMawa5YkHbs1ww5s9x62AOcCfwr8xyQ/3zVkQK066l1j5q9lB71LV0xMTDA9Pd2xjG4Ta+H6i2aPqI8y54nu0KFD7+n+BhnHnmE8+7bn0Q0dFMDfB16qqj8GSPJ54MeBbyU5u6oOtMtKr7fj9wPn9I1fT+9S1f62Pb/eP2Z/u7x1KnBw/kKqahewC2BycrKmpqaGbur2B3Zzy74jX5aXrx5+zhPd9PQ0o7xmq9E49gzj2bc9j26UexSvAJcmeX+7b7AJeB7YA2xrx2wDdrftPcDW9k6mc+ndtH66XZ56K8mlbZ5r5o2Zm+tK4PF2H0OStEKGPqOoqqeSPAJ8BZgFfo/eT/UfBB5Osp1emFzVjn82ycPAc+3466rq3TbdtcA9wFrg0fYAuAu4P8kMvTOJrcOuV5I0nFEuPVFVNwE3zSu/Q+/sYtDxO4GdA+rPABcOqL9NCxpJ0vHhb2ZLkjoZFJKkTgaFJKmTQSFJ6mRQSJI6GRSSpE4GhSSpk0EhSepkUEiSOhkUkqROBoUkqZNBIUnqZFBIkjoZFJKkTgaFJKmTQSFJ6mRQSJI6GRSSpE4GhSSpk0EhSepkUEiSOo0UFEk+lOSRJL+f5PkkfyvJ6Un2JnmxfT2t7/gbk8wkeSHJ5X31i5Psa/tuS5JWPznJQ63+VJINo6xXknTsRj2j+HXgt6vqR4APA88DNwCPVdVG4LH2nCTnA1uBC4DNwB1JTmrz3AnsADa2x+ZW3w68UVXnAbcCN4+4XknSMRo6KJKcAvwkcBdAVf1FVf0psAW4tx12L3BF294CPFhV71TVS8AMcEmSs4FTquqJqirgvnlj5uZ6BNg0d7YhSVoZa0YY+4PAHwP/PsmHgS8DnwImquoAQFUdSHJWO34d8GTf+P2t9t22Pb8+N+bVNtdskjeBM4Bv9y8kyQ56ZyRMTEwwPT09dFMTa+H6i2aPqI8y54nu0KFD7+n+BhnHnmE8+7bn0Y0SFGuAjwCfrKqnkvw67TLTUQw6E6iOeteYwwtVu4BdAJOTkzU1NdWxjG63P7CbW/Yd+bK8fPXwc57opqenGeU1W43GsWcYz77teXSj3KPYD+yvqqfa80foBce32uUk2tfX+44/p2/8euC1Vl8/oH7YmCRrgFOBgyOsWZJ0jIYOiqr6I+DVJD/cSpuA54A9wLZW2wbsbtt7gK3tnUzn0rtp/XS7TPVWkkvb/Ydr5o2Zm+tK4PF2H0OStEJGufQE8EnggSTvA74JfIJe+DycZDvwCnAVQFU9m+RhemEyC1xXVe+2ea4F7gHWAo+2B/RulN+fZIbemcTWEdcrSTpGIwVFVX0VmBywa9NRjt8J7BxQfwa4cED9bVrQSJKOD38zW5LUyaCQJHUyKCRJnQwKSVIng0KS1MmgkCR1MigkSZ0MCklSJ4NCktTJoJAkdTIoJEmdDApJUieDQpLUyaCQJHUyKCRJnQwKSVIng0KS1MmgkCR1MigkSZ0MCklSJ4NCktRp5KBIclKS30vyX9vz05PsTfJi+3pa37E3JplJ8kKSy/vqFyfZ1/bdliStfnKSh1r9qSQbRl2vJOnYLMUZxaeA5/ue3wA8VlUbgcfac5KcD2wFLgA2A3ckOamNuRPYAWxsj82tvh14o6rOA24Fbl6C9UqSjsFIQZFkPfAzwG/2lbcA97bte4Er+uoPVtU7VfUSMANckuRs4JSqeqKqCrhv3pi5uR4BNs2dbUiSVsaaEcf/GvBLwPf11Saq6gBAVR1IclarrwOe7Dtuf6t9t23Pr8+NebXNNZvkTeAM4Nv9i0iyg94ZCRMTE0xPTw/d0MRauP6i2SPqo8x5ojt06NB7ur9BxrFnGM++7Xl0QwdFkp8FXq+qLyeZWsyQAbXqqHeNObxQtQvYBTA5OVlTU4tZzmC3P7CbW/Yd+bK8fPXwc57opqenGeU1W43GsWcYz77teXSjnFH8BPBzST4GfC9wSpL/AHwrydntbOJs4PV2/H7gnL7x64HXWn39gHr/mP1J1gCnAgdHWLMk6RgNfY+iqm6sqvVVtYHeTerHq+rngT3AtnbYNmB3294DbG3vZDqX3k3rp9tlqreSXNruP1wzb8zcXFe2P+OIMwpJ0vIZ9R7FIJ8FHk6yHXgFuAqgqp5N8jDwHDALXFdV77Yx1wL3AGuBR9sD4C7g/iQz9M4kti7DeiVJHZYkKKpqGphu238CbDrKcTuBnQPqzwAXDqi/TQsaSdLx4W9mS5I6GRSSpE4GhSSpk0EhSepkUEiSOhkUkqROBoUkqZNBIUnqZFBIkjoZFJKkTgaFJKmTQSFJ6mRQSJI6GRSSpE4GhSSpk0EhSepkUEiSOhkUkqROBoUkqZNBIUnqNHRQJDknyf9I8nySZ5N8qtVPT7I3yYvt62l9Y25MMpPkhSSX99UvTrKv7bstSVr95CQPtfpTSTaM0KskaQijnFHMAtdX1Y8ClwLXJTkfuAF4rKo2Ao+157R9W4ELgM3AHUlOanPdCewANrbH5lbfDrxRVecBtwI3j7BeSdIQhg6KqjpQVV9p228BzwPrgC3Ave2we4Er2vYW4MGqeqeqXgJmgEuSnA2cUlVPVFUB980bMzfXI8CmubMNSdLKWLMUk7RLQn8DeAqYqKoD0AuTJGe1w9YBT/YN299q323b8+tzY15tc80meRM4A/j2vD9/B70zEiYmJpienh66l4m1cP1Fs0fUR5nzRHfo0KH3dH+DjGPPMJ592/PoRg6KJB8Efgv4Z1X1Zx0/8A/aUR31rjGHF6p2AbsAJicna2pqaoFVH93tD+zmln1HviwvXz38nCe66elpRnnNVqNx7BnGs297Ht1I73pK8j30QuKBqvp8K3+rXU6ifX291fcD5/QNXw+81urrB9QPG5NkDXAqcHCUNUuSjs0o73oKcBfwfFX9m75de4BtbXsbsLuvvrW9k+lcejetn26Xqd5Kcmmb85p5Y+bmuhJ4vN3HkCStkFEuPf0E8AvAviRfbbVfBj4LPJxkO/AKcBVAVT2b5GHgOXrvmLquqt5t464F7gHWAo+2B/SC6P4kM/TOJLaOsF5J0hCGDoqq+t8MvocAsOkoY3YCOwfUnwEuHFB/mxY0kqTjw9/MliR1MigkSZ0MCklSJ4NCktTJoJAkdTIoJEmdDApJUieDQpLUyaCQJHUyKCRJnQwKSVIng0KS1MmgkCR1MigkSZ0MCklSJ4NCktTJoJAkdTIoJEmdRvk/s8fKhhv+28D6y5/9mRVeiSStLM8oJEmdDApJUqdVERRJNid5IclMkhuO93okaZyc8PcokpwE/Dvgp4D9wJeS7Kmq547vynq8dyHpve6EDwrgEmCmqr4JkORBYAtwQgTF0Rggkt4rVkNQrANe7Xu+H/ho/wFJdgA72tNDSV4Y4c87E/j2COM75eblmnkky9rzCWoce4bx7NueF+evHW3HagiKDKjVYU+qdgG7luQPS56pqsmlmGu1sOfxMY592/PoVsPN7P3AOX3P1wOvHae1SNLYWQ1B8SVgY5Jzk7wP2ArsOc5rkqSxccJfeqqq2ST/BPgCcBJwd1U9u4x/5JJcwlpl7Hl8jGPf9jyiVNXCR0mSxtZquPQkSTqODApJUqexDIqFPhIkPbe1/V9P8pHjsc6ltoi+r279fj3J7yb58PFY51Ja7Me/JPmbSd5NcuVKrm85LKbnJFNJvprk2ST/c6XXuBwW8e/71CT/JcnXWt+fOB7rXEpJ7k7yepJvHGX/0nwvq6qxetC7If5/gB8E3gd8DTh/3jEfAx6l9zsclwJPHe91r1DfPw6c1rZ/erX3vZie+457HPjvwJXHe90r8Pf8IXqfbPAD7flZx3vdK9T3LwM3t+3vBw4C7zveax+x758EPgJ84yj7l+R72TieUfz/jwSpqr8A5j4SpN8W4L7qeRL4UJKzV3qhS2zBvqvqd6vqjfb0SXq/s7KaLebvGuCTwG8Br6/k4pbJYnr+h8Dnq+oVgKoal74L+L4kAT5ILyhmV3aZS6uqvkivj6NZku9l4xgUgz4SZN0Qx6w2x9rTdno/iaxmC/acZB3wD4DfWMF1LafF/D3/deC0JNNJvpzkmhVb3fJZTN//FvhRer+wuw/4VFX95cos77hZku9lJ/zvUSyDBT8SZJHHrDaL7inJ36UXFH97WVe0/BbT868Bn66qd3s/aK56i+l5DXAxsAlYCzyR5Mmq+oPlXtwyWkzflwNfBf4e8EPA3iT/q6r+bJnXdjwtyfeycQyKxXwkyHvxY0MW1VOSHwN+E/jpqvqTFVrbcllMz5PAgy0kzgQ+lmS2qv7ziqxw6S323/e3q+o7wHeSfBH4MLCag2IxfX8C+Gz1Lt7PJHkJ+BHg6ZVZ4nGxJN/LxvHS02I+EmQPcE17x8ClwJtVdWClF7rEFuw7yQ8Anwd+YZX/dDlnwZ6r6tyq2lBVG4BHgH+8ikMCFvfvezfwd5KsSfJ+ep/G/PwKr3OpLabvV+idRZFkAvhh4JsrusqVtyTfy8bujKKO8pEgSX6x7f8Neu9++RgwA/w5vZ9EVrVF9v0vgTOAO9pP2LO1ij91c5E9v6cspueqej7JbwNfB/4S+M2qGvj2ytVikX/XnwHuSbKP3iWZT1fVqv748SSfA6aAM5PsB24CvgeW9nuZH+EhSeo0jpeeJEnHwKCQJHUyKCRJnQwKSVIng0KS1MmgkCR1MigkSZ3+H9R7XCsbaRMdAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "pd.Series(predXB).hist(bins=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a399eca",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:58:36.094232Z",
          "iopub.status.busy": "2023-01-30T12:58:36.093832Z",
          "iopub.status.idle": "2023-01-30T12:58:36.389636Z",
          "shell.execute_reply": "2023-01-30T12:58:36.388540Z"
        },
        "papermill": {
          "duration": 0.321638,
          "end_time": "2023-01-30T12:58:36.392269",
          "exception": false,
          "start_time": "2023-01-30T12:58:36.070631",
          "status": "completed"
        },
        "tags": [],
        "id": "0a399eca",
        "outputId": "d1ba4d2b-515b-4741-aded-70c098cb926a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "pd.Series(predCBC).hist(bins=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2ade0bf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:58:36.439865Z",
          "iopub.status.busy": "2023-01-30T12:58:36.438608Z",
          "iopub.status.idle": "2023-01-30T12:58:36.703055Z",
          "shell.execute_reply": "2023-01-30T12:58:36.701885Z"
        },
        "papermill": {
          "duration": 0.292104,
          "end_time": "2023-01-30T12:58:36.706571",
          "exception": false,
          "start_time": "2023-01-30T12:58:36.414467",
          "status": "completed"
        },
        "tags": [],
        "id": "f2ade0bf",
        "outputId": "f9478669-7767-41b3-c069-3840a9dcc30c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD4CAYAAADy46FuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYA0lEQVR4nO3df4xVZ17H8fdHxu2yu8LSsr0SBh20uNpSN25HFn9mFC24mqUmNJkVhawkxFrX1dS4RRNJdkNSorXaamvIgqWVlCKugj/qLqFeq7HQ0v01pYgdF4SxWKwgdqqtHfbrH+cZcxnuPHPn3jt3ZjifV3Iz537PeR6e74XMZ845dy6KCMzMzMbzddO9ADMzm9kcFGZmluWgMDOzLAeFmZllOSjMzCyra7oX0G4LFy6Mnp6epse/8cYbvPvd727fgmYB91weZey7jD3D5Pt+4YUXXouI99Xbd80FRU9PD8eOHWt6fLVapa+vr30LmgXcc3mUse8y9gyT71vSv4y3z5eezMwsy0FhZmZZDgozM8tyUJiZWZaDwszMshwUZmaWNWFQSNol6bykF+vs+xVJIWlhTW2LpEFJJyWtrqnfJmkg7XtQklL9OklPpvpRST01YzZKejk9NrbcrZmZTVojZxSPAmvGFiUtAX4UOFNTuxnoB25JYx6WNCftfgTYDCxLj9E5NwEXI+Im4AFge5rremAr8CFgBbBV0oLJtWdmZq2aMCgi4hngQp1dDwC/CtT+hxZrgb0R8VZEnAIGgRWSFgHzIuLZKP4DjMeAO2rG7E7b+4FV6WxjNXAoIi5ExEXgEHUCy8zMplZTv5kt6SPAv0bEl9MVpFGLgSM1z4dS7e20PbY+OuYsQESMSLoE3FBbrzNm7Ho2U5ytUKlUqFarzbQFwPkLl3hoz4Gr6rcunt/0nDPd8PBwS6/ZbFTGnqGcfZexZ2hv35MOCknvAn4duL3e7jq1yNSbHXNlMWIHsAOgt7c3Wvl1/Yf2HOD+gatfltPrm59zpivjRxyUsWcoZ99l7Bna23cz73r6VmAp8GVJp4Fu4AuSvpHip/4lNcd2A6+kenedOrVjJHUB8ykudY03l5mZddCkgyIiBiLixojoiYgeim/oH4yIfwMOAv3pnUxLKW5aPxcR54DXJa1M9x82AKPXdw4Co+9oWgc8ne5jfA64XdKCdBP79lQzM7MOmvDSk6QngD5goaQhYGtE7Kx3bEQcl7QPeAkYAe6OiMtp910U76CaCzyVHgA7gcclDVKcSfSnuS5I+jTwfDruUxFR76a6mZlNoQmDIiI+OsH+njHPtwHb6hx3DFhep/4mcOc4c+8Cdk20RjMzmzr+zWwzM8tyUJiZWZaDwszMshwUZmaW5aAwM7MsB4WZmWU5KMzMLMtBYWZmWQ4KMzPLclCYmVmWg8LMzLIcFGZmluWgMDOzLAeFmZllOSjMzCzLQWFmZlkOCjMzy3JQmJlZloPCzMyyHBRmZpY1YVBI2iXpvKQXa2q/KekfJX1F0p9Kem/Nvi2SBiWdlLS6pn6bpIG070FJSvXrJD2Z6kcl9dSM2Sjp5fTY2K6mzcyscY2cUTwKrBlTOwQsj4jvBP4J2AIg6WagH7gljXlY0pw05hFgM7AsPUbn3ARcjIibgAeA7Wmu64GtwIeAFcBWSQsm36KZmbViwqCIiGeAC2Nqn4+IkfT0CNCdttcCeyPirYg4BQwCKyQtAuZFxLMREcBjwB01Y3an7f3AqnS2sRo4FBEXIuIiRTiNDSwzM5tiXW2Y42eBJ9P2YorgGDWUam+n7bH10TFnASJiRNIl4Ibaep0xV5C0meJshUqlQrVabbqZyly459aRq+qtzDnTDQ8PX9P91VPGnqGcfZexZ2hv3y0FhaRfB0aAPaOlOodFpt7smCuLETuAHQC9vb3R19c3/qIn8NCeA9w/cPXLcnp983POdNVqlVZes9mojD1DOfsuY8/Q3r6bftdTurn8E8D6dDkJip/6l9Qc1g28kurddepXjJHUBcynuNQ13lxmZtZBTQWFpDXAJ4GPRMR/1+w6CPSndzItpbhp/VxEnANel7Qy3X/YAByoGTP6jqZ1wNMpeD4H3C5pQbqJfXuqmZlZB0146UnSE0AfsFDSEMU7kbYA1wGH0rtcj0TEz0XEcUn7gJcoLkndHRGX01R3UbyDai7wVHoA7AQelzRIcSbRDxARFyR9Gng+HfepiLjiprqZmU29CYMiIj5ap7wzc/w2YFud+jFgeZ36m8Cd48y1C9g10RrNzGzq+Dezzcwsy0FhZmZZDgozM8tyUJiZWZaDwszMshwUZmaW5aAwM7MsB4WZmWU5KMzMLMtBYWZmWQ4KMzPLclCYmVmWg8LMzLIcFGZmluWgMDOzLAeFmZllOSjMzCzLQWFmZlkOCjMzy3JQmJlZloPCzMyyJgwKSbsknZf0Yk3tekmHJL2cvi6o2bdF0qCkk5JW19RvkzSQ9j0oSal+naQnU/2opJ6aMRvTn/GypI1t69rMzBrWyBnFo8CaMbV7gcMRsQw4nJ4j6WagH7gljXlY0pw05hFgM7AsPUbn3ARcjIibgAeA7Wmu64GtwIeAFcDW2kAyM7POmDAoIuIZ4MKY8lpgd9reDdxRU98bEW9FxClgEFghaREwLyKejYgAHhszZnSu/cCqdLaxGjgUERci4iJwiKsDy8zMplhXk+MqEXEOICLOSbox1RcDR2qOG0q1t9P22PromLNprhFJl4Abaut1xlxB0maKsxUqlQrVarXJtqAyF+65deSqeitzznTDw8PXdH/1lLFnKGffZewZ2tt3s0ExHtWpRabe7JgrixE7gB0Avb290dfXN+FCx/PQngPcP3D1y3J6ffNzznTVapVWXrPZqIw9Qzn7LmPP0N6+m33X06vpchLp6/lUHwKW1BzXDbyS6t116leMkdQFzKe41DXeXGZm1kHNBsVBYPRdSBuBAzX1/vROpqUUN62fS5epXpe0Mt1/2DBmzOhc64Cn032MzwG3S1qQbmLfnmpmZtZBE156kvQE0AcslDRE8U6k+4B9kjYBZ4A7ASLiuKR9wEvACHB3RFxOU91F8Q6qucBT6QGwE3hc0iDFmUR/muuCpE8Dz6fjPhURY2+qm5nZFJswKCLio+PsWjXO8duAbXXqx4DldepvkoKmzr5dwK6J1mhmZlPHv5ltZmZZDgozM8tyUJiZWZaDwszMshwUZmaW5aAwM7MsB4WZmWU5KMzMLMtBYWZmWQ4KMzPLclCYmVmWg8LMzLIcFGZmluWgMDOzLAeFmZllOSjMzCzLQWFmZlkOCjMzy3JQmJlZloPCzMyyWgoKSb8s6bikFyU9Iemdkq6XdEjSy+nrgprjt0galHRS0uqa+m2SBtK+ByUp1a+T9GSqH5XU08p6zcxs8poOCkmLgV8EeiNiOTAH6AfuBQ5HxDLgcHqOpJvT/luANcDDkuak6R4BNgPL0mNNqm8CLkbETcADwPZm12tmZs1p9dJTFzBXUhfwLuAVYC2wO+3fDdyRttcCeyPirYg4BQwCKyQtAuZFxLMREcBjY8aMzrUfWDV6tmFmZp3R1ezAiPhXSb8FnAH+B/h8RHxeUiUizqVjzkm6MQ1ZDBypmWIo1d5O22Pro2POprlGJF0CbgBeq12LpM0UZyRUKhWq1WqzbVGZC/fcOnJVvZU5Z7rh4eFrur96ytgzlLPvMvYM7e276aBI9x7WAkuB/wT+WNJP54bUqUWmnhtzZSFiB7ADoLe3N/r6+jLLyHtozwHuH7j6ZTm9vvk5Z7pqtUorr9lsVMaeoZx9l7FnaG/frVx6+hHgVET8e0S8DXwW+F7g1XQ5ifT1fDp+CFhSM76b4lLVUNoeW79iTLq8NR+40MKazcxskloJijPASknvSvcNVgEngIPAxnTMRuBA2j4I9Kd3Mi2luGn9XLpM9bqklWmeDWPGjM61Dng63ccwM7MOaeUexVFJ+4EvACPAFyku/7wH2CdpE0WY3JmOPy5pH/BSOv7uiLicprsLeBSYCzyVHgA7gcclDVKcSfQ3u14zM2tO00EBEBFbga1jym9RnF3UO34bsK1O/RiwvE79TVLQmJnZ9PBvZpuZWZaDwszMshwUZmaW5aAwM7MsB4WZmWU5KMzMLMtBYWZmWQ4KMzPLclCYmVmWg8LMzLIcFGZmluWgMDOzLAeFmZllOSjMzCzLQWFmZlkOCjMzy3JQmJlZloPCzMyyHBRmZpbloDAzsywHhZmZZbUUFJLeK2m/pH+UdELS90i6XtIhSS+nrwtqjt8iaVDSSUmra+q3SRpI+x6UpFS/TtKTqX5UUk8r6zUzs8lr9Yzid4G/johvBz4AnADuBQ5HxDLgcHqOpJuBfuAWYA3wsKQ5aZ5HgM3AsvRYk+qbgIsRcRPwALC9xfWamdkkNR0UkuYBPwjsBIiI/42I/wTWArvTYbuBO9L2WmBvRLwVEaeAQWCFpEXAvIh4NiICeGzMmNG59gOrRs82zMysM7paGPstwL8DfyjpA8ALwCeASkScA4iIc5JuTMcvBo7UjB9KtbfT9tj66Jizaa4RSZeAG4DXahciaTPFGQmVSoVqtdp0U5W5cM+tI1fVW5lzphseHr6m+6unjD1DOfsuY8/Q3r5bCYou4IPAxyPiqKTfJV1mGke9M4HI1HNjrixE7AB2APT29kZfX19mGXkP7TnA/QNXvyyn1zc/50xXrVZp5TWbjcrYM5Sz7zL2DO3tu5V7FEPAUEQcTc/3UwTHq+lyEunr+Zrjl9SM7wZeSfXuOvUrxkjqAuYDF1pYs5mZTVLTQRER/waclfT+VFoFvAQcBDam2kbgQNo+CPSndzItpbhp/Vy6TPW6pJXp/sOGMWNG51oHPJ3uY5iZWYe0cukJ4OPAHknvAL4KfIwifPZJ2gScAe4EiIjjkvZRhMkIcHdEXE7z3AU8CswFnkoPKG6UPy5pkOJMor/F9ZqZ2SS1FBQR8SWgt86uVeMcvw3YVqd+DFhep/4mKWjMzGx6+Dezzcwsy0FhZmZZDgozM8tyUJiZWZaDwszMshwUZmaW5aAwM7MsB4WZmWU5KMzMLMtBYWZmWQ4KMzPLclCYmVmWg8LMzLIcFGZmluWgMDOzLAeFmZllOSjMzCzLQWFmZlkOCjMzy3JQmJlZVstBIWmOpC9K+ov0/HpJhyS9nL4uqDl2i6RBSSclra6p3yZpIO17UJJS/TpJT6b6UUk9ra7XzMwmpx1nFJ8ATtQ8vxc4HBHLgMPpOZJuBvqBW4A1wMOS5qQxjwCbgWXpsSbVNwEXI+Im4AFgexvWa2Zmk9BSUEjqBn4c+ExNeS2wO23vBu6oqe+NiLci4hQwCKyQtAiYFxHPRkQAj40ZMzrXfmDV6NmGmZl1RqtnFL8D/CrwtZpaJSLOAaSvN6b6YuBszXFDqbY4bY+tXzEmIkaAS8ANLa7ZzMwmoavZgZJ+AjgfES9I6mtkSJ1aZOq5MWPXspni0hWVSoVqtdrAcuqrzIV7bh25qt7KnDPd8PDwNd1fPWXsGcrZdxl7hvb23XRQAN8HfETSh4F3AvMk/RHwqqRFEXEuXVY6n44fApbUjO8GXkn17jr12jFDkrqA+cCFsQuJiB3ADoDe3t7o6+truqmH9hzg/oGrX5bT65ufc6arVqu08prNRmXsGcrZdxl7hvb23fSlp4jYEhHdEdFDcZP66Yj4aeAgsDEdthE4kLYPAv3pnUxLKW5aP5cuT70uaWW6/7BhzJjRudalP+OqMwozM5s6rZxRjOc+YJ+kTcAZ4E6AiDguaR/wEjAC3B0Rl9OYu4BHgbnAU+kBsBN4XNIgxZlE/xSs18zMMtoSFBFRBapp+z+AVeMctw3YVqd+DFhep/4mKWjMzGx6+Dezzcwsy0FhZmZZDgozM8tyUJiZWZaDwszMshwUZmaW5aAwM7MsB4WZmWU5KMzMLMtBYWZmWQ4KMzPLclCYmVmWg8LMzLIcFGZmluWgMDOzLAeFmZllOSjMzCzLQWFmZlkOCjMzy3JQmJlZloPCzMyymg4KSUsk/Y2kE5KOS/pEql8v6ZCkl9PXBTVjtkgalHRS0uqa+m2SBtK+ByUp1a+T9GSqH5XU00KvZmbWhFbOKEaAeyLiO4CVwN2SbgbuBQ5HxDLgcHpO2tcP3AKsAR6WNCfN9QiwGViWHmtSfRNwMSJuAh4AtrewXjMza0LTQRER5yLiC2n7deAEsBhYC+xOh+0G7kjba4G9EfFWRJwCBoEVkhYB8yLi2YgI4LExY0bn2g+sGj3bMDOzzuhqxyTpktB3AUeBSkScgyJMJN2YDlsMHKkZNpRqb6ftsfXRMWfTXCOSLgE3AK+N+fM3U5yRUKlUqFarTfdSmQv33DpyVb2VOWe64eHha7q/esrYM5Sz7zL2DO3tu+WgkPQe4E+AX4qI/8r8wF9vR2TquTFXFiJ2ADsAent7o6+vb4JVj++hPQe4f+Dql+X0+ubnnOmq1SqtvGazURl7hnL2Xcaeob19t/SuJ0lfTxESeyLis6n8arqcRPp6PtWHgCU1w7uBV1K9u079ijGSuoD5wIVW1mxmZpPTyrueBOwETkTEb9fsOghsTNsbgQM19f70TqalFDetn0uXqV6XtDLNuWHMmNG51gFPp/sYZmbWIa1cevo+4GeAAUlfSrVfA+4D9knaBJwB7gSIiOOS9gEvUbxj6u6IuJzG3QU8CswFnkoPKILocUmDFGcS/S2s18zMmtB0UETE31P/HgLAqnHGbAO21akfA5bXqb9JChozM5se/s1sMzPLclCYmVmWg8LMzLIcFGZmluWgMDOzLAeFmZllOSjMzCzLQWFmZlkOCjMzy3JQmJlZloPCzMyyHBRmZpbloDAzsywHhZmZZTkozMwsy0FhZmZZDgozM8tyUJiZWVYr/2d2qfTc+5d166fv+/EOr8TMrLN8RmFmZlkOCjMzy5oVQSFpjaSTkgYl3Tvd6zEzK5MZf49C0hzg94EfBYaA5yUdjIiXpndlBd+7MLNr3YwPCmAFMBgRXwWQtBdYC8yIoBiPA8TMrhWzISgWA2drng8BH6o9QNJmYHN6OizpZAt/3kLgtRbGZ2n7VM3ckinteYYqY89Qzr7L2DNMvu9vHm/HbAgK1anFFU8idgA72vKHScciorcdc80W7rk8yth3GXuG9vY9G25mDwFLap53A69M01rMzEpnNgTF88AySUslvQPoBw5O85rMzEpjxl96iogRSb8AfA6YA+yKiONT+Ee25RLWLOOey6OMfZexZ2hj34qIiY8yM7PSmg2XnszMbBo5KMzMLKuUQTHRR4Ko8GDa/xVJH5yOdbZbA32vT/1+RdI/SPrAdKyznRr9+BdJ3y3psqR1nVzfVGikZ0l9kr4k6bikv+30GqdCA/++50v6c0lfTn1/bDrW2U6Sdkk6L+nFcfa353tZRJTqQXFD/J+BbwHeAXwZuHnMMR8GnqL4HY6VwNHpXneH+v5eYEHa/rHZ3ncjPdcc9zTwV8C66V53B/6e30vxyQbflJ7fON3r7lDfvwZsT9vvAy4A75jutbfY9w8CHwReHGd/W76XlfGM4v8/EiQi/hcY/UiQWmuBx6JwBHivpEWdXmibTdh3RPxDRFxMT49Q/M7KbNbI3zXAx4E/Ac53cnFTpJGefwr4bEScAYiIsvQdwDdIEvAeiqAY6ewy2ysinqHoYzxt+V5WxqCo95Egi5s4ZraZbE+bKH4Smc0m7FnSYuAngT/o4LqmUiN/z98GLJBUlfSCpA0dW93UaaTv3wO+g+IXdgeAT0TE1zqzvGnTlu9lM/73KKbAhB8J0uAxs03DPUn6IYqg+P4pXdHUa6Tn3wE+GRGXix80Z71Geu4CbgNWAXOBZyUdiYh/murFTaFG+l4NfAn4YeBbgUOS/i4i/muK1zad2vK9rIxB0chHglyLHxvSUE+SvhP4DPBjEfEfHVrbVGmk515gbwqJhcCHJY1ExJ91ZIXt1+i/79ci4g3gDUnPAB8AZnNQNNL3x4D7orh4PyjpFPDtwHOdWeK0aMv3sjJeemrkI0EOAhvSOwZWApci4lynF9pmE/Yt6ZuAzwI/M8t/uhw1Yc8RsTQieiKiB9gP/PwsDglo7N/3AeAHJHVJehfFpzGf6PA6262Rvs9QnEUhqQK8H/hqR1fZeW35Xla6M4oY5yNBJP1c2v8HFO9++TAwCPw3xU8is1qDff8GcAPwcPoJeyRm8aduNtjzNaWRniPihKS/Br4CfA34TETUfXvlbNHg3/WngUclDVBckvlkRMzqjx+X9ATQByyUNARsBb4e2vu9zB/hYWZmWWW89GRmZpPgoDAzsywHhZmZZTkozMwsy0FhZmZZDgozM8tyUJiZWdb/AT1jXCZyhsHrAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "pd.Series(predXBC).hist(bins=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7727ba48",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:58:36.755452Z",
          "iopub.status.busy": "2023-01-30T12:58:36.755039Z",
          "iopub.status.idle": "2023-01-30T12:58:37.045730Z",
          "shell.execute_reply": "2023-01-30T12:58:37.044298Z"
        },
        "papermill": {
          "duration": 0.318591,
          "end_time": "2023-01-30T12:58:37.049181",
          "exception": false,
          "start_time": "2023-01-30T12:58:36.730590",
          "status": "completed"
        },
        "tags": [],
        "id": "7727ba48",
        "outputId": "ab6df0a9-cfae-475d-dbe4-b23d9ce1d71e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "pd.Series(predLBC).hist(bins=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02c99566",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:58:37.097330Z",
          "iopub.status.busy": "2023-01-30T12:58:37.095918Z",
          "iopub.status.idle": "2023-01-30T12:58:37.392117Z",
          "shell.execute_reply": "2023-01-30T12:58:37.390683Z"
        },
        "papermill": {
          "duration": 0.323834,
          "end_time": "2023-01-30T12:58:37.395609",
          "exception": false,
          "start_time": "2023-01-30T12:58:37.071775",
          "status": "completed"
        },
        "tags": [],
        "id": "02c99566",
        "outputId": "9d8964e2-36ff-4da3-996d-ca963178a83e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "pd.Series(predLB).hist(bins=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92180883",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:58:37.449337Z",
          "iopub.status.busy": "2023-01-30T12:58:37.448315Z",
          "iopub.status.idle": "2023-01-30T12:58:37.761380Z",
          "shell.execute_reply": "2023-01-30T12:58:37.759849Z"
        },
        "papermill": {
          "duration": 0.342432,
          "end_time": "2023-01-30T12:58:37.763952",
          "exception": false,
          "start_time": "2023-01-30T12:58:37.421520",
          "status": "completed"
        },
        "tags": [],
        "id": "92180883",
        "outputId": "12ac5660-46be-4d83-eaca-b9a3469378b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD4CAYAAAD//dEpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAW9ElEQVR4nO3cf6zd9X3f8edreKEkjF9huUWY1mx4a/mRTMElNF0rI2fBTdKaaKA5o8NrkawilqVTugU2qUyNLIE2lhZaqKyA+BEUw2hSUFOaIMhdtJUfgTSN+RGKExA4eDBqSnAaaEzf++N8rBxf3x8fn+N7r2/8fEhX95z3+X6+93WObL/8/X7PPakqJEmay99b7ACSpKXBwpAkdbEwJEldLAxJUhcLQ5LUZdliBzjQjj/++FqxYsXI67/3ve/xtre97cAFmmdLLS+YeaGYef4ttbwwc+ZHH3305ar6h7Murqofqa8zzzyzxvHlL395rPULbanlrTLzQjHz/Ftqeatmzgw8UnP8++opKUlSFwtDktTFwpAkdbEwJEldLAxJUhcLQ5LUxcKQJHWxMCRJXSwMSVKXH7mPBhnX1u+8yr+97Av7zJ+98oOLkEaSDh5zHmEkuTHJS0keG5r9tyTfTPKNJJ9PcszQY5cn2ZbkqSTnDs3PTLK1PXZNkrT54Ulub/OHkqwYWrMhydPta8OBetKSpP3Xc0rqJmDtlNm9wOlV9U7gL4HLAZKcCqwHTmtrrktyWFtzPbARWNm+9uzzYuCVqjoF+BRwVdvXccAVwHuAs4Arkhy7/09RknQgzFkYVfUVYOeU2Zeqane7+yCwvN1eB2ypqjeq6hlgG3BWkhOAo6rqgfYhV7cA5w2tubndvhNY044+zgXuraqdVfUKg5KaWlySpAVyIK5h/Bpwe7t9IoMC2WN7m/2g3Z4637PmeYCq2p3kVeDtw/Np1uwlyUYGRy9MTEwwOTk58pOZOAI+fsbufebj7HM+7dq166DNNhMzLwwzz7+llhfGyzxWYST5L8Bu4LY9o2k2q1nmo67Ze1i1GdgMsGrVqlq9evXMoedw7W13cfXWfV+WZy8cfZ/zaXJyknGe72Iw88Iw8/xbanlhvMwjv622XYT+EHBhO80Eg6OAk4Y2Ww680ObLp5nvtSbJMuBoBqfAZtqXJGkRjFQYSdYCnwB+uar+Zuihu4H17Z1PJzO4uP1wVe0AXktydrs+cRFw19CaPe+AOh+4vxXQF4H3Jzm2Xex+f5tJkhbBnKekknwWWA0cn2Q7g3cuXQ4cDtzb3h37YFX9elU9nuQO4AkGp6ourao3264uYfCOqyOAe9oXwA3ArUm2MTiyWA9QVTuTfBL4atvut6tqr4vvkqSFM2dhVNVHphnfMMv2m4BN08wfAU6fZv46cMEM+7oRuHGujJKk+edHg0iSulgYkqQuFoYkqYuFIUnqYmFIkrpYGJKkLhaGJKmLhSFJ6mJhSJK6WBiSpC4WhiSpi4UhSepiYUiSulgYkqQuFoYkqYuFIUnqYmFIkrpYGJKkLhaGJKmLhSFJ6mJhSJK6WBiSpC4WhiSpi4UhSepiYUiSusxZGEluTPJSkseGZscluTfJ0+37sUOPXZ5kW5Knkpw7ND8zydb22DVJ0uaHJ7m9zR9KsmJozYb2M55OsuGAPWtJ0n7rOcK4CVg7ZXYZcF9VrQTua/dJciqwHjitrbkuyWFtzfXARmBl+9qzz4uBV6rqFOBTwFVtX8cBVwDvAc4CrhguJknSwpqzMKrqK8DOKeN1wM3t9s3AeUPzLVX1RlU9A2wDzkpyAnBUVT1QVQXcMmXNnn3dCaxpRx/nAvdW1c6qegW4l32LS5K0QJaNuG6iqnYAVNWOJO9o8xOBB4e2295mP2i3p873rHm+7Wt3kleBtw/Pp1mzlyQbGRy9MDExweTk5IhPCyaOgI+fsXuf+Tj7nE+7du06aLPNxMwLw8zzb6nlhfEyj1oYM8k0s5plPuqavYdVm4HNAKtWrarVq1fPGXQm1952F1dv3fdlefbC0fc5nyYnJxnn+S4GMy8MM8+/pZYXxss86rukXmynmWjfX2rz7cBJQ9stB15o8+XTzPdak2QZcDSDU2Az7UuStAhGLYy7gT3vWtoA3DU0X9/e+XQyg4vbD7fTV68lObtdn7hoypo9+zofuL9d5/gi8P4kx7aL3e9vM0nSIpjzlFSSzwKrgeOTbGfwzqUrgTuSXAw8B1wAUFWPJ7kDeALYDVxaVW+2XV3C4B1XRwD3tC+AG4Bbk2xjcGSxvu1rZ5JPAl9t2/12VU29+C5JWiBzFkZVfWSGh9bMsP0mYNM080eA06eZv04rnGkeuxG4ca6MkqT55296S5K6WBiSpC4WhiSpi4UhSepiYUiSulgYkqQuFoYkqYuFIUnqYmFIkrpYGJKkLhaGJKmLhSFJ6mJhSJK6WBiSpC4WhiSpi4UhSepiYUiSulgYkqQuFoYkqYuFIUnqYmFIkrpYGJKkLhaGJKmLhSFJ6jJWYST5D0keT/JYks8m+bEkxyW5N8nT7fuxQ9tfnmRbkqeSnDs0PzPJ1vbYNUnS5ocnub3NH0qyYpy8kqTRjVwYSU4E/j2wqqpOBw4D1gOXAfdV1UrgvnafJKe2x08D1gLXJTms7e56YCOwsn2tbfOLgVeq6hTgU8BVo+aVJI1n3FNSy4AjkiwD3gq8AKwDbm6P3wyc126vA7ZU1RtV9QywDTgryQnAUVX1QFUVcMuUNXv2dSewZs/RhyRpYY1cGFX1HeC/A88BO4BXq+pLwERV7Wjb7ADe0ZacCDw/tIvtbXZiuz11vteaqtoNvAq8fdTMkqTRLRt1Ybs2sQ44Gfhr4H8m+ZXZlkwzq1nms62ZmmUjg1NaTExMMDk5OUuM2U0cAR8/Y/c+83H2OZ927dp10GabiZkXhpnn31LLC+NlHrkwgPcBz1TV/wNI8jngvcCLSU6oqh3tdNNLbfvtwElD65czOIW1vd2eOh9es72d9joa2Dk1SFVtBjYDrFq1qlavXj3yk7r2tru4euu+L8uzF46+z/k0OTnJOM93MZh5YZh5/i21vDBe5nGuYTwHnJ3kre26whrgSeBuYEPbZgNwV7t9N7C+vfPpZAYXtx9up61eS3J2289FU9bs2df5wP3tOockaYGNfIRRVQ8luRP4GrAb+HMG/8s/ErgjycUMSuWCtv3jSe4AnmjbX1pVb7bdXQLcBBwB3NO+AG4Abk2yjcGRxfpR80qSxjPOKSmq6grgiinjNxgcbUy3/SZg0zTzR4DTp5m/TiscSdLi8je9JUldLAxJUhcLQ5LUxcKQJHWxMCRJXSwMSVIXC0OS1MXCkCR1sTAkSV0sDElSFwtDktTFwpAkdbEwJEldLAxJUhcLQ5LUxcKQJHWxMCRJXSwMSVIXC0OS1MXCkCR1sTAkSV0sDElSFwtDktTFwpAkdbEwJEldxiqMJMckuTPJN5M8meRnkxyX5N4kT7fvxw5tf3mSbUmeSnLu0PzMJFvbY9ckSZsfnuT2Nn8oyYpx8kqSRjfuEcbvAn9aVT8FvAt4ErgMuK+qVgL3tfskORVYD5wGrAWuS3JY28/1wEZgZfta2+YXA69U1SnAp4CrxswrSRrRyIWR5CjgF4AbAKrqb6vqr4F1wM1ts5uB89rtdcCWqnqjqp4BtgFnJTkBOKqqHqiqAm6ZsmbPvu4E1uw5+pAkLawM/o0eYWHyz4DNwBMMji4eBT4GfKeqjhna7pWqOjbJ7wEPVtVn2vwG4B7gWeDKqnpfm/888Imq+lCSx4C1VbW9PfYt4D1V9fKULBsZHKEwMTFx5pYtW0Z6TgAv7XyVF7+/7/yME48eeZ/zadeuXRx55JGLHWO/mHlhmHn+LbW8MHPmc84559GqWjXb2mVj/NxlwLuBj1bVQ0l+l3b6aQbTHRnULPPZ1uw9qNrMoLxYtWpVrV69epYYs7v2tru4euu+L8uzF46+z/k0OTnJOM93MZh5YZh5/i21vDBe5nGuYWwHtlfVQ+3+nQwK5MV2mon2/aWh7U8aWr8ceKHNl08z32tNkmXA0cDOMTJLkkY0cmFU1f8Fnk/yT9toDYPTU3cDG9psA3BXu303sL698+lkBhe3H66qHcBrSc5u1ycumrJmz77OB+6vUc+hSZLGMs4pKYCPArcleQvwbeBXGZTQHUkuBp4DLgCoqseT3MGgVHYDl1bVm20/lwA3AUcwuK5xT5vfANyaZBuDI4v1Y+aVJI1orMKoqq8D010kWTPD9puATdPMHwFOn2b+Oq1wJEmLy9/0liR1sTAkSV0sDElSFwtDktTFwpAkdbEwJEldLAxJUhcLQ5LUxcKQJHWxMCRJXSwMSVIXC0OS1MXCkCR1sTAkSV0sDElSFwtDktTFwpAkdbEwJEldLAxJUhcLQ5LUxcKQJHWxMCRJXSwMSVIXC0OS1MXCkCR1GbswkhyW5M+T/HG7f1ySe5M83b4fO7Tt5Um2JXkqyblD8zOTbG2PXZMkbX54ktvb/KEkK8bNK0kazYE4wvgY8OTQ/cuA+6pqJXBfu0+SU4H1wGnAWuC6JIe1NdcDG4GV7Wttm18MvFJVpwCfAq46AHklSSMYqzCSLAc+CHx6aLwOuLndvhk4b2i+pareqKpngG3AWUlOAI6qqgeqqoBbpqzZs687gTV7jj4kSQtr2Zjrfwf4T8A/GJpNVNUOgKrakeQdbX4i8ODQdtvb7Aft9tT5njXPt33tTvIq8Hbg5eEQSTYyOEJhYmKCycnJkZ/QxBHw8TN27zMfZ5/zadeuXQdttpmYeWGYef4ttbwwXuaRCyPJh4CXqurRJKt7lkwzq1nms63Ze1C1GdgMsGrVqlq9uifO9K697S6u3rrvy/LshaPvcz5NTk4yzvNdDGZeGGaef0stL4yXeZwjjJ8DfjnJB4AfA45K8hngxSQntKOLE4CX2vbbgZOG1i8HXmjz5dPMh9dsT7IMOBrYOUZmSdKIRr6GUVWXV9XyqlrB4GL2/VX1K8DdwIa22Qbgrnb7bmB9e+fTyQwubj/cTl+9luTsdn3ioilr9uzr/PYz9jnCkCTNv3GvYUznSuCOJBcDzwEXAFTV40nuAJ4AdgOXVtWbbc0lwE3AEcA97QvgBuDWJNsYHFmsn4e8kqQOB6QwqmoSmGy3/wpYM8N2m4BN08wfAU6fZv46rXAkSYvL3/SWJHWxMCRJXSwMSVIXC0OS1MXCkCR1sTAkSV0sDElSFwtDktTFwpAkdbEwJEldLAxJUhcLQ5LUxcKQJHWxMCRJXSwMSVIXC0OS1MXCkCR1sTAkSV0sDElSFwtDktTFwpAkdbEwJEldLAxJUhcLQ5LUxcKQJHUZuTCSnJTky0meTPJ4ko+1+XFJ7k3ydPt+7NCay5NsS/JUknOH5mcm2doeuyZJ2vzwJLe3+UNJVozxXCVJYxjnCGM38PGq+mngbODSJKcClwH3VdVK4L52n/bYeuA0YC1wXZLD2r6uBzYCK9vX2ja/GHilqk4BPgVcNUZeSdIYRi6MqtpRVV9rt18DngROBNYBN7fNbgbOa7fXAVuq6o2qegbYBpyV5ATgqKp6oKoKuGXKmj37uhNYs+foQ5K0sDL4N3rMnQxOFX0FOB14rqqOGXrslao6NsnvAQ9W1Wfa/AbgHuBZ4Mqqel+b/zzwiar6UJLHgLVVtb099i3gPVX18pSfv5HBEQoTExNnbtmyZeTn8tLOV3nx+/vOzzjx6JH3OZ927drFkUceudgx9ouZF4aZ599SywszZz7nnHMerapVs61dNu4PT3Ik8IfAb1TVd2c5AJjugZplPtuavQdVm4HNAKtWrarVq1fPkXpm1952F1dv3fdlefbC0fc5nyYnJxnn+S4GMy8MM8+/pZYXxss8VmEk+fsMyuK2qvpcG7+Y5ISq2tFON73U5tuBk4aWLwdeaPPl08yH12xPsgw4Gtg5TuZRrbjsC9POn73ygwucRJIWxzjvkgpwA/BkVf2PoYfuBja02xuAu4bm69s7n05mcHH74araAbyW5Oy2z4umrNmzr/OB++tAnEOTJO23cY4wfg74N8DWJF9vs/8MXAnckeRi4DngAoCqejzJHcATDN5hdWlVvdnWXQLcBBzB4LrGPW1+A3Brkm0MjizWj5FXkjSGkQujqv43019jAFgzw5pNwKZp5o8wuGA+df46rXAkSYvL3/SWJHWxMCRJXSwMSVIXC0OS1MXCkCR1sTAkSV0sDElSFwtDktTFwpAkdbEwJEldLAxJUhcLQ5LUxcKQJHWxMCRJXSwMSVIXC0OS1MXCkCR1sTAkSV0sDElSFwtDktTFwpAkdbEwJEldli12gKVuxWVfmHb+7JUfXOAkkjS/PMKQJHWxMCRJXZZEYSRZm+SpJNuSXLbYeSTpUHTQX8NIchjw+8C/ALYDX01yd1U9sbjJZue1DUk/apbCEcZZwLaq+nZV/S2wBVi3yJkk6ZBz0B9hACcCzw/d3w68Z3iDJBuBje3uriRPjfHzjgdeHmP9rHLVAd/lvOadJ2ZeGGaef0stL8yc+SfnWrgUCiPTzGqvO1Wbgc0H5Iclj1TVqgOxr4Ww1PKCmReKmeffUssL42VeCqektgMnDd1fDrywSFkk6ZC1FArjq8DKJCcneQuwHrh7kTNJ0iHnoD8lVVW7k/w74IvAYcCNVfX4PP7IA3JqawEttbxg5oVi5vm31PLCGJlTVXNvJUk65C2FU1KSpIOAhSFJ6nJIFsZcHzWSgWva499I8u7FyDkl01yZfyrJA0neSPKbi5Fxqo7MF7bX9xtJ/izJuxYj55RMc2Ve1/J+PckjSf75YuQcytP1sTlJfibJm0nOX8h8M2SZ6zVeneTV9hp/PclvLUbOKZnmfJ1b7q8neTzJ/1rojNPkmet1/o9Dr/Fj7c/HcbPutKoOqS8GF86/Bfwj4C3AXwCnTtnmA8A9DH4H5GzgoSWQ+R3AzwCbgN9cIq/ze4Fj2+1fXCKv85H88NrfO4FvHsx5h7a7H/gT4Pwl8BqvBv54MXOOkPkY4AngJ9r9dxzsmads/0vA/XPt91A8wuj5qJF1wC018CBwTJITFjrokDkzV9VLVfVV4AeLEXAaPZn/rKpeaXcfZPA7NoupJ/Ouan/DgLcx5ZdIF1jvx+Z8FPhD4KWFDDeDpfhRPz2Z/zXwuap6DgZ/Hxc441T7+zp/BPjsXDs9FAtjuo8aOXGEbRbSwZanx/5mvpjBUd1i6sqc5MNJvgl8Afi1Bco2nTnzJjkR+DDwBwuYaza9fy5+NslfJLknyWkLE21GPZn/CXBskskkjya5aMHSTa/771+StwJrGfynYlYH/e9hzIM5P2qkc5uFdLDl6dGdOck5DApjUa8H0Jm5qj4PfD7JLwCfBN4338Fm0JP3d4BPVNWbyXSbL7iezF8DfrKqdiX5APBHwMr5DjaLnszLgDOBNcARwANJHqyqv5zvcDPYn38zfgn4P1W1c66dHoqF0fNRIwfbx5EcbHl6dGVO8k7g08AvVtVfLVC2mezX61xVX0nyj5McX1WL8QF0PXlXAVtaWRwPfCDJ7qr6owVJuK85M1fVd4du/0mS6xbxNYb+fzNerqrvAd9L8hXgXcBiFcb+/FleT8fpKOCQvOi9DPg2cDI/vBh02pRtPsjeF70fPtgzD237Xzk4Lnr3vM4/AWwD3rvYefcj8yn88KL3u4Hv7Ll/MOadsv1NLP5F757X+MeHXuOzgOcW6zXej8w/DdzXtn0r8Bhw+sGcuW13NLATeFvPfg+5I4ya4aNGkvx6e/wPGLyb5AMM/jH7G+BXFytvyzRn5iQ/DjwCHAX8XZLfYPCuiO/OtN/Fzgz8FvB24Lr2P+DdtYif/NmZ+V8CFyX5AfB94F9V+5t3kOY9qHRmPh+4JMluBq/x+sV6jXszV9WTSf4U+Abwd8Cnq+qxgzlz2/TDwJdqcGQ0Jz8aRJLU5VB8l5QkaQQWhiSpi4UhSepiYUiSulgYkqQuFoYkqYuFIUnq8v8Bjg62zj8EzHEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "predLR = np.average(np.array(predsLR),axis=0).clip(0,1)\n",
        "pd.Series(predLR).hist(bins=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ec9f4f4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:58:37.815509Z",
          "iopub.status.busy": "2023-01-30T12:58:37.814487Z",
          "iopub.status.idle": "2023-01-30T12:58:38.096853Z",
          "shell.execute_reply": "2023-01-30T12:58:38.095646Z"
        },
        "papermill": {
          "duration": 0.311213,
          "end_time": "2023-01-30T12:58:38.099613",
          "exception": false,
          "start_time": "2023-01-30T12:58:37.788400",
          "status": "completed"
        },
        "tags": [],
        "id": "1ec9f4f4",
        "outputId": "f42f411b-fa24-4b81-9211-dc5ed1786fc2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "pd.Series(pred).hist(bins=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec8065d4",
      "metadata": {
        "papermill": {
          "duration": 0.024167,
          "end_time": "2023-01-30T12:58:38.148779",
          "exception": false,
          "start_time": "2023-01-30T12:58:38.124612",
          "status": "completed"
        },
        "tags": [],
        "id": "ec8065d4"
      },
      "source": [
        "**Making submission**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "975c4dfe",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:58:38.201153Z",
          "iopub.status.busy": "2023-01-30T12:58:38.200336Z",
          "iopub.status.idle": "2023-01-30T12:58:38.214386Z",
          "shell.execute_reply": "2023-01-30T12:58:38.213295Z"
        },
        "papermill": {
          "duration": 0.042344,
          "end_time": "2023-01-30T12:58:38.216653",
          "exception": false,
          "start_time": "2023-01-30T12:58:38.174309",
          "status": "completed"
        },
        "tags": [],
        "id": "975c4dfe",
        "outputId": "ab971463-572a-455b-cba9-f7379584a380"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>219129</td>\n",
              "      <td>0.004731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>219130</td>\n",
              "      <td>0.002507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>219131</td>\n",
              "      <td>0.001629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>219132</td>\n",
              "      <td>0.003142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>219133</td>\n",
              "      <td>0.001965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146082</th>\n",
              "      <td>365211</td>\n",
              "      <td>0.001656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146083</th>\n",
              "      <td>365212</td>\n",
              "      <td>0.002030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146084</th>\n",
              "      <td>365213</td>\n",
              "      <td>0.001867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146085</th>\n",
              "      <td>365214</td>\n",
              "      <td>0.001353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146086</th>\n",
              "      <td>365215</td>\n",
              "      <td>0.002311</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>146087 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            id     Class\n",
              "0       219129  0.004731\n",
              "1       219130  0.002507\n",
              "2       219131  0.001629\n",
              "3       219132  0.003142\n",
              "4       219133  0.001965\n",
              "...        ...       ...\n",
              "146082  365211  0.001656\n",
              "146083  365212  0.002030\n",
              "146084  365213  0.001867\n",
              "146085  365214  0.001353\n",
              "146086  365215  0.002311\n",
              "\n",
              "[146087 rows x 2 columns]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "submission['Class'] = pred\n",
        "submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2435f5c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-30T12:58:38.268183Z",
          "iopub.status.busy": "2023-01-30T12:58:38.267711Z",
          "iopub.status.idle": "2023-01-30T12:58:38.637406Z",
          "shell.execute_reply": "2023-01-30T12:58:38.636044Z"
        },
        "papermill": {
          "duration": 0.399148,
          "end_time": "2023-01-30T12:58:38.640528",
          "exception": false,
          "start_time": "2023-01-30T12:58:38.241380",
          "status": "completed"
        },
        "tags": [],
        "id": "d2435f5c"
      },
      "outputs": [],
      "source": [
        "submission.to_csv('submission.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 2776.210819,
      "end_time": "2023-01-30T12:58:39.997246",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-01-30T12:12:23.786427",
      "version": "2.3.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}